{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# U-net for segmentation of nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = './data/stage1_train/'\n",
    "TEST_PATH = './data/stage1_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [01:57<00:00,  7.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ...')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:00<00:00, 65.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ...')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASIAAAEZCAYAAAAzAyjYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXvQHcV55n+tTwiQhBAXC4TERQ43Y2wDITYxSaDs9S2x\nQzamiJ04Zlmv8VZlN/Y6ydpsUpXNH65yap31xvGGhDLZsAmxN74kUE4WzPqCHRNsLsHcL5JBINCF\n+0UySPrU+8c5z5n5+puefnvmfDpHpp8q1dHM9OWdnvmmn37et7ud956CgoKCSWLRpA0oKCgoKB+i\ngoKCiaN8iAoKCiaO8iEqKCiYOMqHqKCgYOIoH6KCgoKJo3yICgoKJo4F+xA5597unLvPObfeOffx\nhaqnoKBg34dbiIBG59wMcD/wFmATcBPwXu/93WOvrKCgYJ/HQjGi1wPrvfc/9N7vBL4AnLdAdRUU\nFOzjWLxA5a4BHqkdbwLeEEvsnPOLFhW5qqDgxwl79uzBe+8saRfqQ5SEc+5i4OLh/znwwANxbmCz\nhoux46CcOWk62JGsI5UnVrfVtqZ01rbIPQ7hvU/aGbveVmbT9bb7S5WZQsp2i50xW6znc/Ja7c55\nr63PUdizZ0/j+TD9nj175qWxvG/bt283275QH6JHgaNrx2uH50bw3l8GXAYwMzNTZt4WFLyMsVAf\nopuAE5xz6xh8gN4D/Ko1c/j1DYdt9S++pcdvKjt1vo1RpHrtXOagnql+n6meMNWbW+u2lJXLWtp6\n2JBFWtuy631akLq/GANuu4eYnbG6QnZiYdGx55T7HC115bJD3Y8VC/Ih8t7vds79B+BaYAb4C+/9\nXQtRV0FBwb6PBXHf52JmZsYfeOCBo2NrjzuOMXoXiLmkNKKUVtJFn+rKENrawaozda2jKX+uBtLV\nlibmYK2jq3bWpY7Q7px3omvd404f5tmxYwezs7OmGyiuqoKCgoljYl6zJqTG5oLlC23t1WL5Urbl\n2NdFD4mxi5SHIwaLrV01h9C2GFNs0ohSsD6/NlvHzXRi95mjpXTV2Zqu57ZNCpY2Tz37XBRGVFBQ\nMHFMDSNq+lqH3qQuXgprvaleo81rFno+ZG/KE9KmE3SN0ekSX2TVrFK9Xq4H02KfNX3opWkLkF0o\nj2RbW8bqzvVGdXnPw7+fsCzru9RkXx+75tjYK3dBQUHBGDA1jKgJqd6viaXk6jNdPAJtGkHdvlQd\nbWP2lLdvITSvWN7cuCmLpzK3x7cyxDaNyMroctHG0GP2pdJZWGrb34MFbfF5MfTxlLbakpW6oKCg\nYAGwTzGipl5hXD1OrE4dL1q0aNSD6Nzs7GxjXTm9Wv18E8YVy2LpWfuysFTbW8rK1VZiddXL6dpr\np94di/1ddKY2NN1XLmNNnReamFauZ9WKqf4QWV4U6x9R7AWJpZuZmQFgyZIlACxdupTdu3cD8NJL\nLwFxMTr3A9T2EMNzsWBK68uYI/TnCqshuvzhxmANIm0TkFM2CLl/TDkfvdSx9ePYBbnCeJfOqivK\n0KygoGDimBpG1Oay7vLVzR0mqcfdb7/9ADj44IMBOPnkkwE49NBDeeKJJwC4++7BQpPPPvusyYaU\nbYKFHcQmE6aYkcUVa22zGFLpmyh+LtVPsUsL+0rZnWLPOS71lP25k0P7sMzcIVoT07Oy+1wURlRQ\nUDBxTA0jsriy+wRYpfQaMaJVq1YBcNZZZwGwYsUKAHbs2DG6tm3bNgCeeeaZ1jJjsAiYVnHWyiKt\nulWTXbm6wDjc4311tnEwh5R+01RnV6eB1e62unIF45xwBquIXtz3BQUF+yymhhF1QZOqH8LqJdt/\n//0BOP744wE44IAD5lw/4IADRv/ftWtXL7stOkeOG7fLcb3OWNtY9ZqYbU3lWPSItjpSbWcpu6uL\nfRwerZSWZWUSbR7WvnpNH3T16hVGVFBQMHHsE4wop0cOe/eUBySMF1q+fDlQxQrt3LlzVPajjw6W\n3ZZGlMskcr1obddyPW8W9tJXcwjRxjisml6szBwdxMqqYnVZr1sYnxW5MT9d6srR03I9qLkojKig\noGDimGpG1OXrH2M+4QS/GHN68skngUHcEDCKpt66dSsbN26cU4bYlOrsOtl1HJ6rPp6tcTK4vujq\n/bQwh9j9pZ6HlZW0MfSuDLbtmXSN9wphYX65ZRevWUFBwT6HqVk8f+nSpaNjqxejnialBYV5Q6ak\nX3nPdLx48eLRsTxpirpWZLUirl988cU5NsSWZ7DEyPRlQDrOidy1xuyk8lvTt9Wdmy+nTmuePmV3\nZXJdy++DPnpUW1ll8fyCgoJ9ClOjEdU9Dl2+wOGxtQxpQLHlXZctWwbAYYcdxlvf+lYA3v/+9wPw\n8MMPA3DJJZcAsGHDhsYyYmjTWqz6i3VZ2lj5Te2eq2dYY56aEHvmVi+hpc6uelsuUxqn16krK21C\nqowUE6prRAuFwogKCgomjqlhRJAf31HvzXN7mjCfFjkTs5A2JM3o3e9+N7/1W78FVDP016xZA1Qx\nSLm99TjG+TEmFNPImvKn0qaeSw5DSpXVVa/owqCsNqS8iU3s0lqX1TaVW1+XyfoepRi61VtqQde8\nhREVFBRMHFPDiLz30W1P2vLk9mpNZTQdqxcRU1q3bt2ICQlXXXUVMIgxqtfRN57D0otbY2C6IFVm\nbh31bZa6Mh6rZtJ2vaveYtFQYuiqqy1krFbMhibWpeNxxyaFKIyooKBg4pgaRgT5cSr1PKm4ofA4\nNZZXL/7CCy8A8Gd/9mejNEceeeSccz/60Y/m5LGizbauPX9uzFKbd8lqdwhLHVY7wzpTjClMb3ln\nUtctcV9h3q4sKoe1WVlWysvXl8k3oW2Dy8b0XStyzh3tnPumc+5u59xdzrkPD88f6py7zjn3wPD3\nkK51FBQUvDzQObLaObcaWO29v9U5dxBwC/BLwL8BnvLef9I593HgEO/9x9rKmpmZ8YrXaUNTz2Qd\nQ3cdc9cjrmWjyhBb0vpE0pNiulOOrbmMKJYulr6ezrozSK6Hchw9bK6nzmJjitnk6E6pulKwMiDL\nu9OXyeS0Weq6c47t27cvfGS1936z9/7W4f+fB+4B1gDnAVcMk13B4ONUUFBQEMVYNCLn3HHA6cD3\ngCO895uHl7YAR1jLsfa4bXFEBlsby46Nl6X7vPTSS6M1isI81uM+sNodpk/lh/naltXT04UJWDWg\nriykS9xQysYcFmDVugTr+9tWTi47TL1LbfXH2qarR1Lo/SFyzi0Hvgx8xHv/XNBA3jnXaJFz7mLg\n4uH/+5pRUFCwD6PX7Hvn3H7AV4Frvff/fXjuPuBc7/3moY70Le/9SW3lSCMahzaxEB4AlZPLCHK9\nMzlpxlF2bl1Cbp1NjCFEX90pxmTbPHa5LMuS3+phs77Tlrpz9LEmW0Kbms6n3qOmOnNm33dmRG5Q\n8+XAPfoIDXE1cCHwyeHvVZby6jeQ+iNqo6WCdeJpqs76+b7DI6u7tJ4v9wPU5QNs/eNP5bPY2uWF\nzkFTvtz7yxWQ68MUa2eVmy41TGyzt+tQM2Zr/Vzu31kMfYZmZwO/DtzhnLtteO6/MPgA/a1z7gPA\nRuCCXhYWFBT82GNqFkarD82ELl/Z3CGJlUpbyrb25jk2hr1YbBrMOIdoIcJerytjsIi5bXmb6rQK\nszn2xpDzflrrsA4PrTa25Y2VZbEh93lB3tCsTPEoKCiYOKZqikdfPSenjDC9pRfJ7THHgZielHuf\nFoE/1dvFbIj18k1aWq5QHLM/V6BtyptCF2E91Va5bLnNxW59J1LPJ0eHytVJrSiMqKCgYOKYKkZk\nHYN3cclakeOaTdlg1XP6uNpjZabOt8GqAYXXU56gtja0lpliTE3PrytT7ePByw1D6ONd6/qOh7Za\nvKPWtshts8KICgoKJo6pYUTe+3lLB6S242m61rWntZRjZR3WnnQh2IqVfdWvW1mG1aacnjWXyVo9\nlvXjLh6fprKa7iMsp2tb5jK9+n3lMrdcHS6n7K4ojKigoGDimBpGBOl4lRBtWlGInDiT+vUmnSc3\nFiaGtp7JOo5PaQ0WfSdXh4mdz2Ffqfvoqp2EyNGldL2+tG2TTeH5HPZl9Tha7kuI/d3kspjcd6ct\nby4KIyooKJg4pooRWTWT+tc3tiRlqueJpQvrqPc2ufEaVjTZmorZ6coQYnU31ZWTt54vtqxIU9mp\n+7Oyz9gyvfW2TCH3+baVa9WCrO9pjj1WHTRmU5tnrm+8UAyFERUUFEwcU8WIBKs+0OalSKGLZyvX\nY5Nri+C9T/ZSVs0rR2vJjW0Jz8c2e2xq4xgDyvUqNd1HmK+vfmHV+iwMoutzzLmHsK6YNzpkkX28\ngX1RGFFBQcHEMTWMqEmDyYmJ6aqRxNDWQ3f10KlnSsVHjVOPsninrKwkxZgsz62LR6bJphwGlcum\nYjqOJVLeylBjdadsazovu/Sra9o2/YgjBqs1v/jiiwA89dRTQLXpQ8q2tvbrymBDFEZUUFAwcUwN\nI2rTEWJpmnravvpM6nz9mtWjZbUxp2dN2Wvt3bowx669eE6cTQwxtmKxYVx6YhfNMpdtWLxrYkDa\nCn3p0qXAYOsrgEMPPRSAc845B4CNGzcCcOONNwIVM+oag1bPI5bf9e+wMKKCgoKJY2oYkYXddInb\niJWZywzqvXksTy57scTIWOsIz4d6VBv6xoZ0aYeunsbc55cTC2ONWer63C1l5dyfNKCVK1cCsGbN\nGgBWrFgBwEEHHQRU78CBBx44J1+INu3Pyia7vkOFERUUFEwcU8OI6sjxRll7p9we2BLxmkpj9Zz0\nQVc9ylJmKtYnt62betau3rAcNrM32JaOc9lUrMyUjuicY8mSJQAcdthhABx55JFApRFJA3rwwQcB\n+NGPfgTAM88802hjTuxSjkfbgsKICgoKJo6pYkSpHjcnriHVu3XtsZrs6oqYLV2YXixdTs9l9UjF\nykrl68IEx8EqLezWUtc4PI9970fpZmZmRlrQ6aefDlQakJjP888/DzDaKv2xxx4DqvihtvevjnEw\n2RQKIyooKJg4pooRCV1iZ6weDyvrstZrqcNqY04Ea2zNnJS2MI7evGtsU9PzsuoUseOc2KwYxqXl\nWXSpFBO3xCoJxx9/PADvfve7Adi8eTMAt956K1B50+Ql27Jly5wyYnMDm2zKjTHKZUZT9SGK3azF\njZ8rSObma7Onq8Cass2SNnfY0OcPs6u721J2eD2sM3co3eZcSOXNva+2D5CuxcIpct+Jel2h217X\ntm7dCsC6desAeO6554Bq6KapHrOzs/PKjNlkHZp1dcSUoVlBQcHEMVWMqA+swnZuj1xHWHZs8qqV\nhVh63BxW2FTmQgitKRtzhpix633d33UGkvt8urJr7330PbRMdM7Jt3v3bm6//XYA/vEf/xGAJ554\nAoD169cDlft+586dQBXouHv3bqASsyVeW4JfQ4wrFKUwooKCgonDjTO4ritmZmb8smXLotfH5S7v\ngyaXego52kksb0yUbrLPUl6Yvg8j6qKVpQThro6ANltTeppV+7KI2db2tDLVNkY8MzMDwCGHHAJU\n74g0IE3xuOCCCwC46KKLAPiDP/gDAL75zW8Clbtf+ZomsObqo957duzYwezsrKlBCiMqKCiYOHpr\nRM65GeBm4FHv/Tudc+uALwCHAbcAv+6939m3nqBOoDkYLzbe78r8+rCwriEFsXNtebqytSa7Ur1x\nCrm6Vtu1XBtynnOK4ViZUay8NntSLM1y39J6pAWFy4KsXbsWgA9+8INzzp922mkA3HTTTUClEYlh\ntWlF435XhHEwog8D99SO/xD4tPf+eOBp4ANjqKOgoODHGL0YkXNuLfALwCeAj7rB5/BNwK8Ok1wB\n/Ffg0lRZbRpMeL7JkxD7mvfVwJryp3pKq8enrRfp6u2Kxa20sRMrm+waB9WmNVj1Gys76dNDWzSg\ntvTjKDvWLm3vg/4fajuaDLthwwYADj/8cKDSjK677jqgijMKl5ptsivGGlP3lUJfRvQ/gP8M6K//\nMOAZ7/3u4fEmYE1TRufcxc65m51zN0+DYF5QUDA5dGZEzrl3Atu897c4587Nze+9vwy4DAZes6be\nMkdryI0XGiesWkiq96jfd8pLlrLByijqTDRmT9eym+7Lar+V2eQ851x7c71mbUwilidEjAE1lZNq\n11NPPRWoRgsnnXTSnONXvOIVJpua7AnPh8j9u+szNDsb+EXn3M8DBwArgD8GVjrnFg9Z0Vrg0R51\nFBQUvAzQ+UPkvb8EuARgyIh+23v/a865LwLnM/CcXQhcZS2zC7PYG4wnhZQuk+vhqrPD+rl6WWHd\nsXQWT49V4xJiE21z6rJ6X2I9cGzTwCY201XbisGi7YVlh+dTWxPlyBWhPfKm3XPPwId07LHHAnDH\nHXcAcNdddwFwww03AJXXLDb3rIl9jfvvbiHiiD7GQLhez0AzunwB6igoKPgxwtREVi9dujTbQ2RB\nbkRon7K7errGCet9dbn/XOaUE1djyduU3/JcrSwxpUnGPJBtdlqfQ8zWLu+M8mgpWW0zpPNiPmJC\n4a/lHiyaUYmsLigo2KcwNbPvLR6HLuPnNr2iDksPlOqNrZ4f60zsHHT17LRpKLm9tYURdvV+peoM\nNaOmNNYYplTdbZ6i3Lbp8k6n7BO0RKyYTkxXS3m+mjTZXG9gCoURFRQUTBxTw4jqSPUa4/AsWNlN\nFw9d1563fj6lV1i9LeNkfhZGkLLJ+gytnsacdyGXweWWZ7Gz67HQhZ2I+fTdFrrNnr7MrjCigoKC\niWNqGFFOrEJ9zG/9qsd6HGt8TpNd42QhKXvb7GrKZ43QzbGvqw7VFNPT18OY48myxiaF560rcObY\nHbPNGpNlYc0pWKP2m8pfKE9wYUQFBQUTx9QwojpyWE6uZiJ0iS+yegqs+kYbcjWiPppKLhMax/2F\nZaW2RYqtkZOjpTRda7IlPG/VxixsM4fJtZVj8Xb29Ww11TVub5lQGFFBQcHEMTWMqOtY08pK2uYi\nWe2wegbGMW626GP1dKn0qfWJ6shZy6gNbXpHjAmF12N1WvURi63WdyBs6z66VOx+UtpZ032H73gM\nXZ9bW/3j0EOhMKKCgoIpwNQwoi5j3pw0Vi9UmyZjZV9WD0gbrHqEVb9JMZC2OmNI6R1N5YX2hL24\n1aMzDiYUyxP7DVcwbFsNNJUmdt3KnML/N+XJ9Uy2tblVU7WOGkJMzYeoj1u5niY3wMoqalvK6Hrd\nkscSXtCWz9IeuUOwLkJl7ke6K9XPEePDPyLtFa/JotqqWb/afufpp58Gqkmk9TJSH6CYbTmdXW7H\nl3o3YkPypiF1WGZf0boMzQoKCiaOqWFEdVhd0000tatQ3Jda5tRtGcqNi2VZmIaVdlt73j5MNmX/\nOETqGFPQshlHHHEEAIceeihQLa0qphRuZPjCCy+MyrEOl2Lnuwznc/OM87nFjnP/fgojKigomDim\nkhFZv+hNgVZh75DLlNoEvRxRtg2p3qTJ1pQYnXLLt7ldU2X3sbtebluarkw2hSaWEt6nGI80oSOP\nPBKoNiQUAxJjkia0fPlyALZv3w4MnkFMfE4x7th5C1NcaCdK099ZzP5wi3QrCiMqKCiYOKaKEY1j\n7JoK00+lC8/Xv/B99aewzBijyPFsWQMDLW7xXC+ZlRla9Borq8zVxnLud//99wdg2bJlc47FhFSW\nNiTcuXOwk3q4zAZULEvtrmOVIVZlXZzMEoi6kKxSiLGq8D3LRWFEBQUFE8dUMSIrE+ry5Y9t8RMy\nBYuHzhqvEZYpWKY15GpbXVmW9/bNHMehs/X1xMXqsqSP6TW6f7EUMR2xGKXbsWMHAFu3bgUqZlSv\nS2UdcMABQLXts/Qn6UmKQZLnLff+mu4rha4e4SaNKFZmV+91YUQFBQUTx1QxIiGla9TH4tb4HytT\nsHzJ+7CPNttyooFjZVhtqafrGxWbsqXpWq4OaPX0NJUba5tQfxFbefTRwebEK1euBCpm9PjjjwOw\nbds2oGJO9XKlK61ZswaoGJHqUpliTKpLZdWjtJvut8ljHENOG7VdXyjtqY7CiAoKCiaOqWFETWwg\nZxkKa6+eipWxeNNi27KkYK1zHEjFzuTAyvRyyu7CRLvY1hQvFbNFrOSxxx6b86vrqUXoZ2ZmOOSQ\nQwA4+OCDgWp+mliV6tB1RWU/+eSTwPxtn2N/C23tZdXhBGvsmQVddajCiAoKCiaOqWFETV/dnLih\nPhpCW/qmOVkxVmXtDXKXCe2CLvOGrBs/WnvUJl0jZJO53pYUO256D2LsIsZsd+/e3WpL7PkuWrRo\n5B1TVLbKEiMSxHzkeQu1obCuLqzEemz5G7AwsbY6UiiMqKCgYOKYGkbUhj6zgnPHw6ny2sq0esvG\nwYRCj2KOhhDakrI7d/uZ8Lhuk7WMGMu0xrPUbY4xvtz7Sb07e/bsGcUFyQOnGftiPLr+1FNPAfOj\ns2N1ddER+8Zs5WixfXXOXozIObfSOfcl59y9zrl7nHM/7Zw71Dl3nXPugeHvIb0sLCgo+LGH6/Ml\nc85dAXzHe/8559wSYCnwX4CnvPefdM59HDjEe/+xtnJmZma85vdAmnFY4lRSPUwKTb1HXyaT0lj6\nPAsro7O0oZWBWvW4Nk0s9WzD5VnDaOcwvzSZJjtTelROnFfTdefcyEt29NFHA5XXTIxIsUhPPPHE\nnPNtUfaW47b76fvedolv896zY8cOZmdnTRk6MyLn3MHAzwGXDyve6b1/BjgPuGKY7Argl7rWUVBQ\n8PJAZ0bknDsNuAy4G3gdcAvwYeBR7/3KYRoHPK3jGMSIxsEMhFArCM/vq0ixqtAjZLnfJu9W0/mU\nLpNjf2p7J9mvX2ktYs6rVq0CKoakOJxnnnkGqJhR3bYw/ienjZpsD8/Xy5TXTIxo165dQLXedSqC\nOnZ+HKy5C9Ptoidt37594RkRA6H7DOBS7/3pwHbg44GRHmhsOefcxc65m51zN+/rH4eCgoJ+6MOI\njgRu9N4fNzz+WQYfouOBc733m51zq4Fvee9Paisr1Ihy0HUcbNUJcjQiiybS175Ynann2JauS2+3\nUFBd4aqIWj/6pJMGr9IrXvGKOTaKadxyyy1AxZC899E1f6waV0xjavLkxbx6oQ25LCy0uQ1dmU8b\n+0p5DJvy7BWNyHu/BXjEOaePzJsZDNOuBi4cnrsQuKprHQUFBS8P9I0j+o/AlUOP2Q+Bixh83P7W\nOfcBYCNwQdfCcyI+c3vvmD6Q6h1z7O06rs/x0FnLtnjVcnWKLkwppXEJ0n40d+vVr341AIcffjgw\n3xul9McccwxQzeESU2qzP9SjYlHQoa4T03kgPv9wnJpPDDkxZE02NZUzzr+TJvT6EHnvbwPObLj0\n5j7lFhQUvLww1ZHVVn3EkjZEF00l5V3KrSNVd1MdMR2qr1aWssNyPrzepkel8oqdaKcMaUW6b7ER\nMR5FKMcilZsQ6lCqS/uayRZFQWteWLiqYr2u3MjjhfAUp+poYz5N5TWtQ22Ja8rBVH2Icv/Q2/L2\nRRMVzaWnOWJgeN0qDuairZ1y3dkxdHHnh9CHRkuqvvTSS3Ouhx8DpXvkkUeAyl3eVqcWMdNwbvXq\n1UD1YVK6tWvXAtUH6YEHHgDg2WefnWND/b5jz6nr4vI5GJfToe1dGbdjo0x6LSgomDimihHFGIfF\nLd61F7cG6+UEBqZsswjHuSEAueJ23YbcxfO72tbkXAjtCutQgOIPfvADoGItgoZLYiupxehh/rBv\n3bp1wHwmpONwMTMxJA0L9VtnzbnDn9T1Lgw9VzpQu3QJP+kSZjCn7qzUBQUFBQuAqWFETS7rtuDC\n+nHsnAUL4ZLu6r7PCZ7sizbXbE5eC5p69dwAOWlA0mVC5pSjySiNFrBXKICOVZZ0qVC0FZPSNA6l\nq7vzrW56q/A/DoYeez/D62H+Ju0rZX/uO1IYUUFBwcQxNYwoxxXfdL0vg7CMca1er1iZqd6xzTsx\n7sA3CwNM9cJdg0ibykrZmWuDghKXLFky0nrEWMRgwi18tJhZLLBRdSmdPHN1xqSyrO9IiJx3P/Ue\nddWpmrRAa7BryrYYCiMqKCiYOKaGEdXRpffP7Z27aEIphpPyPuXEEYXnuqJPvEfX3jvWHl2CJ0PE\nAhWVXyxGOs7JJ588ClDUltH3338/UE2M3bx5M1BtfigGJYj5aFGzDRs2ABWjqt9f6h1Jxcr19bxa\nykgxpZy4va7XQxRGVFBQMHFMJSPKQcpDFetxumgvMXYRY0Jdw/3bruUypC5R6mHeWJvFevfQU5Vj\ne652FNOGTjjhBABOPfVUDjroIKBiNtry5zvf+Q4ADz/8MFB5zUJtSMxHy7sqbqhtGknus899Tk1x\nRCmkyrTEXoVltXmdc961wogKCgomjqlhRJYYkzBtl16hT7xQagPChahzHNHMTceWaOpcL18sfY4e\nFd6v2Il1MwTdl5YPWbx48agMLTd72GGHAdXiaj/84Q8BuPvuuwFYs2YNUGlFil2SRhRb5KzpHbY+\nt9TzEnLiiHLfu1Q8XFNZfUYYdRRGVFBQMHFMDSNqiw1q62FzPQE5PUrKxlSP08djlSorhVjP2lbO\nOPW0pnKbkHrGqecVptOi+du2bQMG88IU9xOLkNZ5zWvT/DWVHVsYrUt0cwwpfS2nzljZXeK9lG+h\n/74KIyooKJg4poYRgT3Wog5r3MW4bGqq2zq+71O/FdaeqX7eGh1rva9Ye+zZsyd7pr/VwxiWq1n4\nu3fvHs2aFzRvLWRKYjypxfZjelYXzTLEODW83LZuOx9u66S1nNRmYZS5ZWG6ObZmpS4oKChYAEwV\nI0p9mftoLONiSG1lp+qwbvZYj9DNZVdWdlNHbmRtSvuyRIynnqn1fkNWImilRi22D9UcM8UNKU2o\n/cSW4Q1takqX+7xi6WM21GH11qbqTOmsixYtGsVYKSZL2zsprzYrkEb3wgsv8Pzzz7faV0dhRAUF\nBRPHVDEiIScepa8ek8O2cnWLFENI1VNHzryt+vUu84Zi7Z4bWd7FLisrjpWnY0U/33zzzTz22GNz\n7NSx0sRNJtN/AAAgAElEQVTsTm2L3WRrX4YnWOKIuowMmsqMPV8dL168eKSzaSNUrcUk1qO4LTGi\npUuXjlbNtKAwooKCgoljahhR3eOQ03ukeq0YrNHCbdesMTCWskPEIqEt2kFunVaGNw7kRninGEas\nF1c77dy5czRHTL146OGxsqyUh3ZvtJclhq4r2mKZ1J5ikeHWSlrlsr7ud45dhREVFBRMHFPDiLrq\nC13n0Vi3nG6yK6UF9Z0X1lRvauW/VNmxcnN6rVTkdcqGet1Wr1lXDbDOjOTRCdmSlQmF12N1NbGV\nlH3hccyz2sTeUu3elTGFtu/atWsUdR5CmpEYUX3lgsKICgoK9ilMDSOCPG9Z3zpSdTf1WF01nxQr\nyentrbEhOfpGLqOJ9eZd2Ne44rtijLdeZ4wJpcqyMos+9xLbAdYSkxWD9e8mxUr37Nkz0tWksymy\nWvvM6Vhes8WLFxdGVFBQsG9hqhhRbg/UVkYqKtbKHHI0ipRXJVbmOJhCWJZ6f0uMjzWuRGXpVx4S\nzWKXPqA5XLKhPntd/095SFPXU+9G3UbNj9JKi+HuHdaYppgtbW0c09UE2aYyUjP9c2KXxgk9a8UL\nKbJazz68v9y5Zr0+RM65/wT8O8ADdwAXAauBLwCHAbcAv+6935lZ7pzjLh+oLkGDbfmbwgusLujU\nx6zL0Cy1PG1uaEHTtfDlUp0K9z/66KOB6uXUh0jTKuTalcv3/vvvHwW5abpFzO6uIrVskE1HHnnk\n6I9Fi+dv3LgRqBY8C/9oYh/B1HvZNMyNvWdqQy3CpqHNQw89BMyfkBui/j5a28za+YbvWH2KR7jB\ngIZs4fOcnZ3Nenadh2bOuTXAbwJneu9PBWaA9wB/CHzae3888DTwga51FBQUvDzQd2i2GDjQObcL\nWApsBt4E/Orw+hXAfwUu7VNJLNDK4lrvO8Sp93YxO2I2WIeFTbZaA/isNjTVESI1PNUwYtWqVXN+\nJWCuW7cOgA996ENA1Vuq97zyyiu5+uqrgarnTw3VrEK/fkNWtmzZshHb0LW1a9cCVS8uxhYiZIJi\nTjnDjtB+tcWxxx4LVGKv7Nf0E7G38D5jx7FzbbZY27YeAqElVEIWrOcosXr37t3zhpdt6MyIvPeP\nAp8CHmbwAXqWwVDsGe/97mGyTcCapvzOuYudczc7524el+ekoKBg30RnRuScOwQ4D1gHPAN8EXi7\nNb/3/jLgMoCZmZk5XyLrGLYp7bg+ak09s9U9nRqLj1OUT13v4+4NtQfpBGJCYgranuf0008HKmZ0\n6623AtUi9eecc85oofpNmzYBVQ86bte4euOZmZkRMws3X9Qi+mIhoXtfTC+0IWbrokWLomlUltru\nuOOOm2OTmIZ0tRAWzSz3fUq9p/XAXD0naXxKq2ev+1C6F198ce9oRMC/Ah703j/uvd8FfAU4G1jp\nnNMHbi3waI86CgoKXgbooxE9DJzlnFsK/Ah4M3Az8E3gfAaeswuBq3ILzlH9LawpzGNJH+Zrs8Pq\nKYmxlHGGK4RIeVSavIGxBdxXrFgBVL17qA/cfvvtwGCbZ6g0IrnL165dy6mnngrA1772tUa7rGwy\nBtlS9+KErnGVEYYdhFNz6qzKYuOePXui7nlpKq961auAyv0t79jWrVuB+dtYC03vqzU4N4bUe1s/\nVlnhZpPSvPRbTyd2ZEEfjeh7wJeAWxm47hcxGGp9DPioc249Axf+5V3rKCgoeHmgl9fMe//7wO8H\np38IvL5PuTHkMIbcnjXlZarXbe3FrXEeTedTrMsaw9R2H2G+mH2qQ8uE6jgMDJQn7HOf+xwAb3/7\nQDKUFrNq1Sp+8IMfABVbarKjjly2KVajHvuggw4aTcwUOwkZT9iWobcstDWGuo6oX9V94oknApWm\nojKlDYkRpZ5T03sYi4Pqi3pQbGz5GbGe0PNYH61YUKZ4FBQUTBxTNcUjhTZ9I0SsJ7X2OBZtwqpL\nxepIjfHbyo6hqxbWVr/yKLZFvbnSqVeUJ0zeMnmjTjnlFGDQ63/jG9+Yk8eqj1nbVixHPfQjjzzC\nK1/5yjnXxOS0tEXM4xpjGm0sTf+XrnTkkUcCFZuUDYrLue++++bYG3vvmmLXrKzeej2GJqYeS2NJ\n24TCiAoKCiYONw3BhDMzM15j6TosX/BxecNyvGy5npxcNmYpM1VXytYmBtIWHwOVvqHIZEF6jOZu\nxcqdnZ1NRifnetFiECOZmZkZecfCpSrCLXCEsO7U8rz18/q/6gojqOVx1JZG0tVCb1kser/JYxzG\nP6Xeyz5e2hxs376d2dlZUyWFERUUFEwcU82IQli8S2HaVLrwuqXO2LVU2TmaktXLl7LfYnOqZwy9\nSPXlQGH+Vs1tNlm8kk2wss6m90DnwiU3FCkuZhQyoVSbh1i0aNE8z5sYkOKI1FZPPvkkMH8h/3pZ\ndZtVTtNcrpi9YdvmLmHcB957duzYURhRQUHBvoN9wmtmZQV15MbVWLxlMf0iVXYMueyszc7cdPX7\nztXRYls0h+m6eOjCMqw2pfLBfE9djI0IISuJ6TaKKl66dOno//KC6Xfbtm1z6ootWxvGbGmenhan\nF3vbunXraF5aWFbs1/quN523bvuU0rhiKIyooKBg4pgaRtTWM1uYUOorb/UkCE3j6a7Rv6no6PC4\nqS26RojnsEkr44x5vHKXB22qOxWF3qfsVJxQqIVJQzr++OOByhOmeWxKf8wxxwCD1QuVRh5ExQmt\nX79+Tt5YW4VLsobz+2ST955HH310Tlm5mmXsOMxXX1UghvC55epQhREVFBRMHFPDiHJ6vhxvTHic\n0nks0c59mFvT9aYezBp1nbqfcMyeExeVq4H1YTFWrSt1PacnjpUpVvL61w+mTL7vfe8Dqjlz0pY0\ng/76668HBvqNyhSDOfjgg4FKVxNDitkgHUssRwxLTEjXV6xYwZYtWxrzpJDShELU46OsXs/cd6Aw\nooKCgoljahhRG3J62r5RpeE2PE15c+uOzRvKifPI7WFyeqhcZpPL9Ornc+OhUtqRhQnlejHlsXr/\n+98PVHPlNG9MjEksRbrP97///ZE2pCh0ebm0hvb999/fWGd4P/KI6V0RwxIbW7x48cibF1vVMXZ/\nXRhr19gqKwojKigomDimkhFZtYq2tLmRuqHHpE8MjNXW2PU2/SaE1WsWq6POUmKMLOYR6cucLPch\nhAw13FnDqtvVz8VWohTD0eoBP/dzPwdU0dDrhmtyC9J/XnzxxdGcMUErMMb2KYs9J7Eu6T9a+aC+\naWUuQx8Hm0lpRV3LLoyooKBg4pgaRlTvma0ekra0qS+0lXW19frWsXbINGK6SFsvEjKA0D6rTW3t\nYo2eDfNKv5BmEduZoz77PtVLp/SzHK0pN8ZMmss111wDVEzouOOOA+Cmm24CqlUVn3vuuVE+5RWD\n0bVHHnlkzn2kGGu49nb4bJ5//vnkypG570IOUrFzuZiaD1Hbi9OUJkwbS9NVWG1Kl+siTrk2ww+T\n/pAlgkL14uqPO1wuouuwqD4cyxmO1svW5NdwGoIg17XKffrpp0d/vGFgX66bPna+LaAuvM/YEE1t\nrWVttQWSBOhwsqnE7OXLl4/uRx+vBx98EJi/DU/KWSLRW0uYKJ8+Pk899VR0cfpcV7vlb6BLeEQO\nytCsoKBg4pgaRgT5AlibOzjGGCwLTjXZYOkJuoYMaGgjZvGud71rFKwml7GC5jZs2ADMn7CZYl1t\n7ZS7PERYlvLL7S2GIGZXH2YooO/OO++ck9c6TSH2fGP3l9ODh8NACcxioRpmhQGEYj8rVqwYsUSl\nlftebRBOH1EZ4UYEGuJp+V0tkyMmuWPHjiyBvn5/1vRtecfNkAojKigomDimihGl3MZCXd+IpbH2\nrGGZbfmselMKYajAypUrAXjLW94CwNve9raRHiG2JJfxZz7zGaByLVsZQ9v9dhX8Q+ag7ZTV20sz\nUr5ly5ZxwgknANUSqVrAPvW8UoGNsSBRSyhEGMSqdKEWFLrmBTGk7du3R9sy3HJaTFeitp7n888/\nP6duMSDVXXdWhGEXQo7uWU9nyTcuzTVEYUQFBQUTx1QxohCWsa615+yKejmhjhHTVqzjZ3nJTj/9\ndADOP/98AI466qgRy9Ci69KMxDZiPU/XiY/1cykmGh7rV71+GIwndjczMzO6Jo+atJSU3bG2jDGj\ncMnWeh2x+4g9z9RzrtsS2qH7XbNmDVBNnNVz1Dug3wceeACoNKKYBmbxMlufX+y46b5SGmrXkIDC\niAoKCiaOqWFEbR6wEH2CC4XUdIamL30qZqWr10yM4Sd+4ieAQfCbNAFpB9/97ncBePzxx1vvq4v3\nLLdHDc/Lg6dthdT7K124fQ9UjEiBfmGdoV6TYkzyVomVafkM7/3IPukuofZj7c1Tz7H+jsgOMVr9\niiGF96f0ihsKJ7K2sRdrcGiI3PtuOtdFZ2pCYUQFBQUTx9QwIguaeiJrpG0sfexL3jQhMpa2a5Sz\neuZ7770XgOuuuw4YxBPpmrwot912G9DsPWm735yo2ZjdKW+TGIf0DfX+8gYKzz//vNnrIs0k1HVC\nJismpDibo48+Gqi0GOfcKKp548aNQOWpyvEsttlaTxfar8XTYtNgQhtSU2CavJ1WJp5iLZa/Gav2\nmqvNJhmRc+4vnHPbnHN31s4d6py7zjn3wPD3kOF555z7jHNuvXPudufcGVnWFBQUvCxhYUR/CXwW\n+N+1cx8Hvu69/6Rz7uPD448B7wBOGP57A3Dp8DeJpq9uTh5rmpSuox5WY/m6zhFG1KZiWUKE6VWO\nYmr+9E//FBjEmNT1IoC77roLqOJKYmXG0GXsHmurWM8qD5jmaMkbWGeXmkMlL2DMkxU7HzIhaUHH\nHXccUMXn6PqiRYtGHiqxEkV3qy1jc7aELlHEYYR03XMIFbOVDfqNLXLWx2uW4x2rX29jP3290SGS\njMh7/23gqeD0ecAVw/9fAfxS7fz/9gPcCKx0zq0el7EFBQU/nuiqER3hvd88/P8W4Ijh/9cAdTfI\npuG5zSRg+cLm6B252pDG7op8fe1rXwtUSz1s2bJl1ONr07wuPWXTfag31JYzDz300GipCfXWsSUf\nUjEuuRvdtdkZO69fsQBtcyPbxVL27Nkzak8xo9hzCTdxDL1pel5agvWIIwavoJismMfMzMw8vUYe\nO7Gy2P2EdYdo8ybpeUmXEtOpr6xQv095Q8N3q483qq9G1OYxtraRFb3Fau+9d85lRzE55y4GLh7+\nv68ZBQUF+zC6foi2OudWe+83D4de24bnHwWOrqVbOzw3D977y4DLAGZmZnzbmLdNo+gayRlCPZXm\ne/3O7/wOUPXu119/PX/zN38DVPEy4UZ7YW8e0z1iPZIYRMgG6rB6CXN6UKs2YI03CWOgxIK890nG\nEz7jGKPTeW1EKA1GjKLOiEI9Jly4zcr4UjbWy9GzlodOzCjcvlrtEOqPlrbO9RjnoilWKfW3ubfj\niK4GLhz+/0Lgqtr59w+9Z2cBz9aGcAUFBQWNSDIi59zngXOBw51zm4DfBz4J/K1z7gPARuCCYfJ/\nBH4eWA/sAC6yGtIUp9OWtun/dViU//p5eV/krVq7du2c3zPPPHOkdVxxxRVz6lDMiiKHFU8jTUm9\nXmquUxtivXDuWkJt6cIVIvUrlhGumaOywtnrYR1NDC/Ma31egvJp9r7aWveg/PV1exSTpd++bDpn\ny6kwqlvIZV9tI4eurMQaJ9VUR6oMK5IfIu/9eyOX3tyQ1gO/0cuigoKClx2mJrK66aubincI/x8r\nzwL1VNu2DeQusQCtqbNz584RO3rXu94FVLqE5lZJE7nnnnsA+Id/+Aeg0pRCFhC7hzbbu+oAFiak\neU5aM0jRymIbWrs5NmNex9JnmmxMeV1ivyH0vKQ/ia0pmlsxQzMzMyMGpLShBzLFIFJakn5nZ2fN\nLCXlhRJSni1LWVYPcqy8LshlSGWuWUFBwcQxNYwI7D1T/Vc9Xz0Cuq2MEEonBnTttdcCFTsQCzrq\nqKPmzRNS7ystRfOcFMsi/eKrX/0qMF9bCW1o6kVSzCd1PTaWr0coi9mJCSneRhAzkkYW2yxQCHWr\ntlimGPMJ9aaYVqJnoXWjNa+sni/UZayeKat2kuPFzb0esui2v5Eu8UEWWO6r6T3LYUWFERUUFEwc\nU8WIYuPq8FfM5KCDDuLVr341UGk5ikgOPVapOqUbPPzwwwD8+Z//OVCxnWXLlo0ics8991ygYg4r\nVqwAKl1CUbTSjsSQwjWP+zAhIVcjCttwxYoVvPKVrwQqhhdqPGHsS+74v82zF66omCojdT7HI5li\nEGG6FJNt82hZdykJ0ealsmpaVg3S2h5NeazezhgKIyooKJg4pooRCamvqljKG9/4Rl7/+tcDVa8t\n9vGNb3wDSM/dEcL9pXQsdrN9+/Z5s8tVdxhprXlDiqYN97TKGe8LKU9ILH+TJgTVHmQnnHDC6P/h\n6oFqC0UHS4ex7s7aFB0dMiDpT2K0aivVHT6/UGcLf8M2bmJSsbazbusdu8+2cyHjy2UlbbDqg7ks\nu0n7SmmO+l2yZEkWO9qnPkT1m4TB0g8amumDIVetllbVi2xFSKWbxG+55y+//HIAzjhjsOyS/nju\nvvtuAP75n/95jm0pV20bugqNYX79QUiMX7Zs2ag9ZafSaLiqNpX4nhsoV/9wqcPQZpIaviqgVHkU\nHKqJqU8//TRQtXG4DEgsQHLXrl3ztukO7YsNZVKu+LCc+rQL63Coq4vce2/+oMTqTIUU1I9TbRQO\n+Y866qhRx21BGZoVFBRMHFPDiOr0LzUMUQ+3bdu2Ua+tYYN67djE01gvERtu1Gm66lXvLMZz8803\nzylLQ5nYsq4hwiGMpWfNFQXD+5GN27dvnydOiwVqiKnF2cI2zR1eLF68eDQdRoumabmVk08+GaiG\n3Xqe11xzDVAtlavQATkIxKx0D3r+YnHbt28f3auGzqnhuZB6d5pYQm5wZC7DbavLGtgYCwkI0zUd\np1ikhtpnnnnmyPFjQWFEBQUFE8fUMCKwux3Vs333u98daR0am95yyy1AWhtKjXWbAujCPGIOsicU\nSK29XtN9puyJ5Q3Px37FJDdt2jRaSkPXpBUpODBkEnU76/lSS+guXryYY445BoBf/uVfBuC8885r\ntF+QbWrrTZs2AdXSsL/yK78CVIud/cu//AtQbUSwadOmeYwvdj/hch7WYNH6Qv/hBGchVqY1wLHp\nOVqDDGP3IbtTz7X+7qfsqm83nrMoX2FEBQUFE8dUMSLLlxmq3nzbtm18/vOfn5MmXKoiVkfOuFj5\nYq7jGEJPVajTWBhSyDKsQXWxHjfcAuiFF14Y6TWnnXYaMPB4QMUuvvKVrwCV/hJbWCzl2l2yZMmI\nuWi5lRROPPHEOem1JOw73/lOAM4555w56ZVOmw3UmXG4MFrsOVgDN2WLAlwfeuih0cRgTZ6OvYe5\nG3w25U955nQsRhi+jzE9tI0RpTyL0uOee+65ZDBxHYURFRQUTBxTw4jaYhVizKG+xU+9HGt99TrC\n8ylPVz1t2MMoLkdTPnQ93DomtZlevUxr8KA1+E7ttmrVKt73vvfNsVv2qadXcGhOXEjTPdR7Vm3p\nc+qpp7bmVRudcsopQOUl+5mf+ZnG9FrqQ3UeeOCBo4BNsaOQFYbLgig2SZOB9RzVZtLQxIje+MY3\nAgOW9r3vfQ+oWKSWGo69TzEW09U7WkfIgBQ0qqlJsknPNWSMlvcxtFuM6IEHHpi39VUbCiMqKCiY\nOKaGETV9+VPspm2cnPJ0xNK39UChPeFmjOG2x1pWQ9HfX/7yl4FqKdlw8f22aQm5SGkP+t1///1H\nMTnqzV7zmtcAVSzPT/7kTwKVxyqGmEevPn1G02EUm6QytdyKdAWdVzyQ2Jk0JrV9iBtuuAGo2nb5\n8uXzJiXLE6c4KcUmCfLIvfWtbwWq56j08shpSyRF0p9xxhkjO8UqrrzySmD+VJWQlVmnleQwJXnF\n1GZin9IAxfy0oJ80QXlLm2LxUn8vyrNhw4bCiAoKCvYtTA0jqn91Y5MPQ9RjKayerKYy6vW3MaZw\nzK0eVrET6mk++tGPAtWSsoKYxUUXXQTMnwzbNDZPaQap82EsR1OU+oMPPgjA2972NqDSEPQrD1Du\nxM0w3a5du0bbayveS0xI8/VUh9iHdA1FZKdiU+pbTQMce+yxnH/++UAVjS0bFBn/pS99Cag8rj/7\nsz8LwEc+8hGgmpcnSBP6u7/7O6BiHieeeCInnXQSULEuTZDWnDmxTM2lS2mAqSjopnOhJiRGLo+i\nFrhTPmlhYkaaOdBUZ0qrrG+1ncPsCyMqKCiYOKaGEdXZTWy83MQOus7Fskal1ntg9XwaW+s33NL4\nTW96U2OZ0h6kJUljaIpnic0LsnrNUkxK5c3Ozo7s0a8YkHrzDRs2APFtr0Ob2+qUHnPrrbfOKVPx\nN2GkvNhHjAnJ4yOGJZvlXTvttNN43eteNydPqOHJgyet56d+6qfm2BJC+d7whjcA1WJ811577Whx\nOXn5xD7uvfdeYP4mmql5e0IO01dbiQFqG3XZFr7beu7hKhH1kUlKswqRq3MWRlRQUDBxTA0jausR\n2q6lvEOp9FYv23777Tca97/5zYMt3cR8vvOd7wBw++23A1UPqbG5vFHyBKnO2MaLbfEbIazR6DFs\n3bqVP/qjPwLgzjvvnHMf999/PzDfi5KyITbXzHs/YgTyhmmGttIo5kfsMcaExKyuumqwybDYzLHH\nHgtULCBkQ1CxrXCNI52XbhVDGDMjprF69eqRtqV3RYxNdcXi3qzP16IRCdIw9auyxIDkyQv1qyY2\nk/p7anoPrTF9UBhRQUHBFGBqGFHbbOLUnJompHrp1BytcBx98MEHj/SKT3ziE0DllZBW8KEPfQio\nvGbSjOTJUS+u6N+QYViYUK6WELvfejS4NCBtGBCLdQnzhnFPMQ9d3eawTDEGsa5wiV55ctSW4SoL\n0pbOOussoGKrQrhhQR3yFm7evBmo5tJ99rOfBeCDH/wgAGefffacfNL2lE/HUOlpV1999Zxj6xZG\nseck1J9vSl/S+6a2VFyPmJAY0Pr16+ekt+pWTfZ2RWFEBQUFE8fUMKL6XLP6ubbjWDnQPzJV6dQD\nn3vuufz2b/82UGkCgjw08rZ87nOfA6qxtyB9IPQ+hYyiyXsWQ+hVi52vrwkEFZvbf//959UhBqeI\nXPWUYgxiGbqPJrtjCBmRtCJFXIslao6Won2lvahuRadL/3jLW94CVDExwt133z3SZxS7Iyb0xS9+\nEaiek65L81Md73nPe4DBqoMAf/VXfwVUnjDdw4oVK0b6kliI7I55kWLxb7GVG4S2aGcd6350H5oB\nIFukWep6TAO0jFZy9KAmFEZUUFAwcSQZkXPuL4B3Atu896cOz/034F3ATmADcJH3/pnhtUuADwCz\nwG9676+1GpPSdSzz0VJehlgPk4rMXrVq1Zy1VqDqfTXWlmagXjvmIUnpVE0I15RJrQIZeqz0K5u1\nqeLZZ589slf3pfgZMT/1lIq30a/miym/xfMT2hdbDVKMSefD3lwsTSs0hkxILGXLli2jslS2mIyY\nUqil6H50/Cd/8idAxb6kCYVzqRYvXjxiF2pvsRLrs1Y+3a9+lb7ORlPsXmmlAel+5TXTcVs8W8zW\nGINry9MGCyP6S+DtwbnrgFO9968F7gcuGRpzCvAe4NXDPH/qnGuenVhQUFAwRJIRee+/7Zw7Ljj3\ntdrhjcD5w/+fB3zBe/8S8KBzbj3weuCfLcZYPVtNeazHsbqEsE6xmmuuuWYUm6J9zcQMpAN87Wtf\nm5MnZb+F8Qnh/DZpPNJ81HuLtYU6lMrWnC3FDmmOF1QR1ddeOyCxYniqU9HCipGRrhNGC8fuo+4B\nCveNE3MIN3WUhzH01MkGRUkLuu+vf/3rwIDlqX3Dmf/hipP1aPP6ebWtEHtndu/ePc9LZ90ZRIxX\n8xa1AoJWzxRr+6d/+qfRPaRmIOhYbRJrS0sUdCr+bho0on8L/N/h/9cAj9SubRqeKygoKIiil9fM\nOfe7wG7gyg55LwYuHv4fSM+jquWNpg+1HvU0ocYS82DF1lfZuHEjn/70p4Fq3K5eSmWEvaE1tqKp\ntwlXfZT9YgDa7lrMQIxC0dDyNolZhHUoivo1r3nNiPGI8WkdaHmP1JOGOo2ioKWVhMxBaPOqhbpE\nuPV3qHEpnWzWnDVFYn//+98HKla3ZMmSkSai5xTGDcVWJEzF0zSdD1dUiLH78LmGM+UVFyWGJCar\n+9y8efOortgefin9MHZ/Mdtj99xURy46f4icc/+GgYj9Zl/V/ihQ58prh+fmwXt/GXAZwMzMjB+W\nqWs0HdfyNtkDVEMV/dFoOc9XvepVQLXFsTZF1B9k+FDDunfv3j16cVMPNmfI1YS6u1R5NcFWlF0h\nA/oYaGqDfiU0f+tb3wLmb8l9/fXXAwOxOlzIXm2mP1zVrftXkJ7+eDS5MnTNWwLjwmvhtJfwQ6Rf\nDbP++q//es796IOsj8/y5ctHQY/hEC3cjDNmW44Qm5IChPB+9Nx+4Rd+AZj/IdYHS5No99tvv3kd\nX6zDtg7hhNSGDW11dkWnoZlz7u3AfwZ+0Xu/o3bpauA9zrn9nXPrgBOA7/c3s6Cg4McZFvf954Fz\ngcOdc5uA32fgJdsfuG74tbzRe//vvfd3Oef+FribwZDtN7z3pj1Fmr6sOYwi7DnkztUGfuppNJSR\nW1iCc9gDp0TGJrtiFDe28WBYTtP18JqGJCpT96lfud4lQstVreA19aKaInHppZfysY99bE6Z3/72\nt+fYp7I17NO0ixgLbZvMG+uNY9NElE5laqii4aCGWQo90HKov/d7vzcqV/enCbaa4qC2yB3SxJiC\n9/Ftd1J16L50PmxLudhXr149uh6bkmGVOiwjja7IHQVYvGbvbTh9eUv6TwCfyLKioKDgZY2pmeJh\nGcoGBCIAAAeBSURBVId2cXdrsmQY8CbRVzpHuIi5RRBPjaVjrMqiOYT1hwxAy9Kq59R9KEhNzEla\nknQRlaOQg7//+78fsSMFOWoBeC2hIRYpt7eWCVFdoeBveV6pZxlrf4nvOi82Jk1Iy7xqus3TTz89\nsl9TO0J3fQopgbYpbRvLrR+HjE9tKWYvGzXdpr5xoyWAtA1WxtSkWabqWIiAxoKCgoIFxVQzohyN\nKOxZ1HNqYqMYknpHaScaZ1uW7oxpO6lj9Wrhwu4xxuS9n3dNesYdd9wBVN4/aQthmL56fU3CVE8q\nRlXfclpMR8tdiAnJ0yh29Y53vAOoFiMTy4pNNwnboa6hCKntncP0MRYjZiRPmHDQQQeN2KOWkU31\n7qH7OnY/TdNtYqw49u7ovVNbimWKAckLqHTS6V566aVsxm1t46Z0KWZn3VghhsKICgoKJo6pYURt\nnqIwTf3rHJsEKs+IJiF+6lOfmlNW6Dlp264ltCs3viSMBZKuo2OxmvokzJhWpR5SUxjkJZIWpPtR\nOnkFxYjC7a6dc6M8Wg5j48aNALz2ta+dcx+KxwkXWU95X5pYTIpNpnrU8B2R10wxTsLixYtHemDK\nTutUnDC/hT3HylLbSLO78cYbgUrrErO97bbbgCrurWnSa65+k4rbqz+TWJqcJWDaUBhRQUHBxDE1\njAjyp3rUz4V5w0hp9eKx2BAhtYBV+P82hLZJlxEj0uL7l1xyCVBtT/zZz352XmRtPcIbKk1BkyCl\nkYR1xSZ01u9F7FDeMzEhnZe2oq2Wdb7rFkdNaSyMtH49nCQqTUVamTYwOPPMM0fn9A7EnnEuC4td\nb7sWe99CDTBcTlhsuT4hN/YOp7Qgq1bUNErJ9Z5ZURhRQUHBxOHGGU3ZFTMzM37ZsmXZY/Sma7Hx\ncuoLbo2AbcubiitSLy5tSMtqiAnJo3XBBRfMmweV6v1SvWJbfqVVrJW8ZVoaVVHZih8KPW9WNtP2\n/GLHIeTBCxd40xw8MUAtVrdixQpuuOGGOXbH5l7F2LIlojple6pMIZwhEL5b9fLCslJetK5/C/U4\nIiucc7zwwgvMzs6ahg+FERUUFEwcU8GInHOPA9uBJyZtSwSHM522TatdML22TatdML22dbXrWO/9\nKywJp+JDBOCcu9l7f+ak7WjCtNo2rXbB9No2rXbB9Nq2N+wqQ7OCgoKJo3yICgoKJo5p+hBdNmkD\nWjCttk2rXTC9tk2rXTC9ti24XVOjERUUFLx8MU2MqKCg4GWKqfgQOefe7py7zzm33jn38QnacbRz\n7pvOubudc3c55z48PH+oc+4659wDw99DJmTfjHPuX5xzXx0er3POfW/Ybv/HObdkQnatdM59yTl3\nr3PuHufcT09Dmznn/tPwOd7pnPu8c+6ASbWZc+4vnHPbnHN31s41tpEb4DNDG293zp0RL3nBbPtv\nw+d5u3Pu75xzK2vXLhnadp9z7m3jsGHiHyI32An2fwLvAE4B3usGO8ZOAruB3/LenwKcBfzG0JaP\nA1/33p8AfH14PAl8GLindvyHwKe998cDTzPY6nsS+GPgGu/9ycDrGNg40TZzzq0BfhM40w+2Sp9h\nsAvxpNrsL5m/Y3Ksjd7BYOOJExhsuXXpBGzbu7s5K1R8Uv+AnwaurR1fAlwyabuGtlwFvAW4D1g9\nPLcauG8Ctqxl8LK+Cfgq4BgEmS1uase9aNfBwIMM9cba+Ym2GdVmn4cymNz9VeBtk2wz4DjgzlQb\nAX8OvLcp3d6yLbj2r4Erh/+f8/cJXAv8dN/6J86ImNLdYZ1zxwGnA98DjvDebx5e2gIcMQGT/geD\nLZw0oegw4Bnv/e7h8aTabR3wOPC/hsPGzznnljHhNvPePwp8CngY2Aw8C9zCdLSZEGujafubWPDd\nnKfhQzR1cM4tB74MfMR7/1z9mh90A3vV1eiceyewzXt/y96s14jFwBnApd770xlM1ZkzDJtQmx0C\nnMfgQ3kUsIz5w4+pwSTayALXYzfnHEzDh8i8O+zegHNuPwYfoSu9918Znt7qnFs9vL4a2LaXzTob\n+EXn3EPAFxgMz/4YWOmc05pSk2q3TcAm7/33hsdfYvBhmnSb/SvgQe/94977XcBXGLTjNLSZEGuj\nqfibcNVuzr82/FDCAtk2DR+im4ATht6MJQyEsKsnYYgbrH9wOXCP9/6/1y5dDVw4/P+FDLSjvQbv\n/SXe+7Xe++MYtM83vPe/BnwTOH9Sdg1t2wI84pw7aXjqzQw22JxomzEYkp3lnFs6fK6ya+JtVkOs\nja4G3j/0np0FPFsbwu0VuL29m/PeEuoSQtnPM1DmNwC/O0E7foYBPb4duG347+cZ6DFfBx4A/h9w\n6ARtPBf46vD/rxy+BOuBLwL7T8im04Cbh+3298Ah09BmwB8A9wJ3An/FYHfiibQZ8HkGWtUuBizy\nA7E2YuCI+J/Dv4c7GHj+9rZt6xloQfo7+LNa+t8d2nYf8I5x2FAiqwsKCiaOaRiaFRQUvMxRPkQF\nBQUTR/kQFRQUTBzlQ1RQUDBxlA9RQUHBxFE+RAUFBRNH+RAVFBRMHOVDVFBQMHH8f+i9MhhVmhA5\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0d5adb940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASIAAAEZCAYAAAAzAyjYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2YgkNWcjktTc/wOfluXuoKJcXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0d5b72dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our Keras metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define IoU metric ->????????????????????????\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Build and train our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 128, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 16) 448         lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 128, 128, 16) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 128, 16) 2320        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 32)   4640        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 64, 64, 32)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 64, 32)   9248        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 32, 32, 32)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 64)   18496       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 32, 64)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 64)   36928       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 16, 16, 64)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 128)  73856       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 128)  0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 128)  147584      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 8, 8, 128)    0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 256)    295168      max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 8, 8, 256)    0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 256)    590080      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 16, 16, 128)  131200      conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 256)  0           conv2d_transpose_9[0][0]         \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 128)  0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 128)  147584      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 32, 32, 64)   32832       conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 128)  0           conv2d_transpose_10[0][0]        \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 32, 32, 64)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 64)   36928       dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 64, 64, 32)   8224        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64, 64, 64)   0           conv2d_transpose_11[0][0]        \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 64, 64, 32)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 64, 64, 32)   9248        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 128, 128, 16) 2064        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 128, 128, 32) 0           conv2d_transpose_12[0][0]        \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 128, 128, 16) 0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 128, 128, 16) 2320        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 128, 128, 1)  17          conv2d_56[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 3:45 - loss: 0.6953 - mean_iou: 0.0000e+00\n",
      " 32/603 [>.............................] - ETA: 2:39 - loss: 0.6439 - mean_iou: 0.2096    \n",
      " 48/603 [=>............................] - ETA: 2:15 - loss: 0.6031 - mean_iou: 0.2797\n",
      " 64/603 [==>...........................] - ETA: 2:02 - loss: 0.5507 - mean_iou: 0.3172\n",
      " 80/603 [==>...........................] - ETA: 1:53 - loss: 0.5244 - mean_iou: 0.3413\n",
      " 96/603 [===>..........................] - ETA: 1:46 - loss: 0.5135 - mean_iou: 0.3579\n",
      "112/603 [====>.........................] - ETA: 1:40 - loss: 0.4941 - mean_iou: 0.3694\n",
      "128/603 [=====>........................] - ETA: 1:35 - loss: 0.4837 - mean_iou: 0.3782\n",
      "144/603 [======>.......................] - ETA: 1:30 - loss: 0.5786 - mean_iou: 0.3849\n",
      "160/603 [======>.......................] - ETA: 1:26 - loss: 0.5626 - mean_iou: 0.3904\n",
      "176/603 [=======>......................] - ETA: 1:22 - loss: 0.5499 - mean_iou: 0.3948\n",
      "192/603 [========>.....................] - ETA: 1:18 - loss: 0.5522 - mean_iou: 0.3984\n",
      "208/603 [=========>....................] - ETA: 1:15 - loss: 0.5474 - mean_iou: 0.4010\n",
      "224/603 [==========>...................] - ETA: 1:11 - loss: 0.5401 - mean_iou: 0.4030\n",
      "240/603 [==========>...................] - ETA: 1:08 - loss: 0.5339 - mean_iou: 0.4048\n",
      "256/603 [===========>..................] - ETA: 1:05 - loss: 0.5271 - mean_iou: 0.4062\n",
      "272/603 [============>.................] - ETA: 1:01 - loss: 0.5214 - mean_iou: 0.4076\n",
      "288/603 [=============>................] - ETA: 58s - loss: 0.5200 - mean_iou: 0.4087 \n",
      "304/603 [==============>...............] - ETA: 55s - loss: 0.5123 - mean_iou: 0.4097\n",
      "320/603 [==============>...............] - ETA: 52s - loss: 0.5097 - mean_iou: 0.4106\n",
      "336/603 [===============>..............] - ETA: 49s - loss: 0.5032 - mean_iou: 0.4114\n",
      "352/603 [================>.............] - ETA: 46s - loss: 0.4983 - mean_iou: 0.4121\n",
      "368/603 [=================>............] - ETA: 43s - loss: 0.4932 - mean_iou: 0.4127\n",
      "384/603 [==================>...........] - ETA: 40s - loss: 0.4885 - mean_iou: 0.4134\n",
      "400/603 [==================>...........] - ETA: 37s - loss: 0.4842 - mean_iou: 0.4139\n",
      "416/603 [===================>..........] - ETA: 34s - loss: 0.4834 - mean_iou: 0.4145\n",
      "432/603 [====================>.........] - ETA: 31s - loss: 0.4794 - mean_iou: 0.4149\n",
      "448/603 [=====================>........] - ETA: 28s - loss: 0.4762 - mean_iou: 0.4154\n",
      "464/603 [======================>.......] - ETA: 25s - loss: 0.4727 - mean_iou: 0.4158\n",
      "480/603 [======================>.......] - ETA: 22s - loss: 0.4681 - mean_iou: 0.4161\n",
      "496/603 [=======================>......] - ETA: 19s - loss: 0.4644 - mean_iou: 0.4165\n",
      "512/603 [========================>.....] - ETA: 16s - loss: 0.4590 - mean_iou: 0.4168\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.4580 - mean_iou: 0.4171\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.4535 - mean_iou: 0.4174\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.4505 - mean_iou: 0.4177 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.4482 - mean_iou: 0.4179\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.4464 - mean_iou: 0.4182Epoch 00001: val_loss improved from inf to 0.36737, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.4437 - mean_iou: 0.4184 - val_loss: 0.3674 - val_mean_iou: 0.4296\n",
      "Epoch 2/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.3343 - mean_iou: 0.4289\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.3337 - mean_iou: 0.4289\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.3171 - mean_iou: 0.4289\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.3028 - mean_iou: 0.4292\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.2922 - mean_iou: 0.4297\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.2967 - mean_iou: 0.4302\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.2811 - mean_iou: 0.4307\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.2706 - mean_iou: 0.4311\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.2620 - mean_iou: 0.4317\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.2557 - mean_iou: 0.4323\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.2470 - mean_iou: 0.4330\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.2462 - mean_iou: 0.4338\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.2436 - mean_iou: 0.4347\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.2400 - mean_iou: 0.4355\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.2396 - mean_iou: 0.4364\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.2344 - mean_iou: 0.4374\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.2327 - mean_iou: 0.4384 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.2317 - mean_iou: 0.4395\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.2312 - mean_iou: 0.4407\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.2306 - mean_iou: 0.4418\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.2316 - mean_iou: 0.4430\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.2283 - mean_iou: 0.4443\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.2263 - mean_iou: 0.4455\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.2251 - mean_iou: 0.4468\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.2225 - mean_iou: 0.4480\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.2215 - mean_iou: 0.4492\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.2199 - mean_iou: 0.4505\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.2191 - mean_iou: 0.4517\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.2168 - mean_iou: 0.4530\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.2140 - mean_iou: 0.4542\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.2123 - mean_iou: 0.4555\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.2127 - mean_iou: 0.4567\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.2116 - mean_iou: 0.4580\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.2084 - mean_iou: 0.4592\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.2063 - mean_iou: 0.4605 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.2040 - mean_iou: 0.4617\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.2024 - mean_iou: 0.4630Epoch 00002: val_loss improved from 0.36737 to 0.14603, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.2020 - mean_iou: 0.4639 - val_loss: 0.1460 - val_mean_iou: 0.5188\n",
      "Epoch 3/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1418 - mean_iou: 0.5267\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1673 - mean_iou: 0.5279\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1937 - mean_iou: 0.5291\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.1877 - mean_iou: 0.5302\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.1787 - mean_iou: 0.5311\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.1738 - mean_iou: 0.5322\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.1744 - mean_iou: 0.5334\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.1732 - mean_iou: 0.5346\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.1724 - mean_iou: 0.5357\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.1723 - mean_iou: 0.5369\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.1683 - mean_iou: 0.5380\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.1605 - mean_iou: 0.5390\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.1615 - mean_iou: 0.5401\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.1567 - mean_iou: 0.5411\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.1571 - mean_iou: 0.5422\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.1563 - mean_iou: 0.5432\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.1556 - mean_iou: 0.5442 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.1523 - mean_iou: 0.5452\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.1526 - mean_iou: 0.5462\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.1518 - mean_iou: 0.5472\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.1515 - mean_iou: 0.5481\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.1503 - mean_iou: 0.5491\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.1498 - mean_iou: 0.5500\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.1508 - mean_iou: 0.5509\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.1487 - mean_iou: 0.5518\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.1472 - mean_iou: 0.5527\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.1452 - mean_iou: 0.5535\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.1433 - mean_iou: 0.5544\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.1429 - mean_iou: 0.5553\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.1432 - mean_iou: 0.5561\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.1430 - mean_iou: 0.5570\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.1425 - mean_iou: 0.5578\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.1422 - mean_iou: 0.5586\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.1410 - mean_iou: 0.5594\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.1392 - mean_iou: 0.5602 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.1392 - mean_iou: 0.5609\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1382 - mean_iou: 0.5617Epoch 00003: val_loss improved from 0.14603 to 0.12618, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.1372 - mean_iou: 0.5623 - val_loss: 0.1262 - val_mean_iou: 0.5958\n",
      "Epoch 4/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1436 - mean_iou: 0.6003\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1340 - mean_iou: 0.6009\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1143 - mean_iou: 0.6016\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.1203 - mean_iou: 0.6022\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.1101 - mean_iou: 0.6027\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.1257 - mean_iou: 0.6032\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.1374 - mean_iou: 0.6038\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.1430 - mean_iou: 0.6044\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.1422 - mean_iou: 0.6050\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.1398 - mean_iou: 0.6056\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.1347 - mean_iou: 0.6062\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.1410 - mean_iou: 0.6068\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.1428 - mean_iou: 0.6074\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.1426 - mean_iou: 0.6079\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.1400 - mean_iou: 0.6084\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.1381 - mean_iou: 0.6090\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.1395 - mean_iou: 0.6095 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.1403 - mean_iou: 0.6101\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.1406 - mean_iou: 0.6106\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.1421 - mean_iou: 0.6111\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.1423 - mean_iou: 0.6116\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.1408 - mean_iou: 0.6121\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.1401 - mean_iou: 0.6126\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.1390 - mean_iou: 0.6131\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.1408 - mean_iou: 0.6135\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.1391 - mean_iou: 0.6140\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.1371 - mean_iou: 0.6145\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.1366 - mean_iou: 0.6149\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.1343 - mean_iou: 0.6154\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.1322 - mean_iou: 0.6158\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.1328 - mean_iou: 0.6163\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.1314 - mean_iou: 0.6168\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.1310 - mean_iou: 0.6173\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.1300 - mean_iou: 0.6177\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.1311 - mean_iou: 0.6182 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.1299 - mean_iou: 0.6187\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1299 - mean_iou: 0.6192Epoch 00004: val_loss improved from 0.12618 to 0.11894, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.1283 - mean_iou: 0.6195 - val_loss: 0.1189 - val_mean_iou: 0.6398\n",
      "Epoch 5/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1530 - mean_iou: 0.6428\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1142 - mean_iou: 0.6431\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1068 - mean_iou: 0.6435\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.1096 - mean_iou: 0.6439\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.1156 - mean_iou: 0.6443\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.1158 - mean_iou: 0.6447\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.1130 - mean_iou: 0.6451\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.1170 - mean_iou: 0.6455\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.1167 - mean_iou: 0.6459\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.1163 - mean_iou: 0.6463\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.1169 - mean_iou: 0.6466\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.1166 - mean_iou: 0.6470\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.1161 - mean_iou: 0.6473\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.1167 - mean_iou: 0.6477\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.1178 - mean_iou: 0.6480\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.1170 - mean_iou: 0.6484\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.1145 - mean_iou: 0.6487 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.1148 - mean_iou: 0.6491\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.1149 - mean_iou: 0.6494\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.1160 - mean_iou: 0.6497\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.1181 - mean_iou: 0.6501\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.1165 - mean_iou: 0.6504\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.1159 - mean_iou: 0.6507\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.1157 - mean_iou: 0.6511\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.1170 - mean_iou: 0.6514\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.1153 - mean_iou: 0.6518\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.1158 - mean_iou: 0.6521\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.1160 - mean_iou: 0.6525\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.1173 - mean_iou: 0.6528\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.1178 - mean_iou: 0.6532\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.1183 - mean_iou: 0.6535\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.1194 - mean_iou: 0.6538\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.1201 - mean_iou: 0.6542\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.1194 - mean_iou: 0.6545\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.1198 - mean_iou: 0.6549 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.1190 - mean_iou: 0.6552\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1194 - mean_iou: 0.6555Epoch 00005: val_loss improved from 0.11894 to 0.10356, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.1178 - mean_iou: 0.6558 - val_loss: 0.1036 - val_mean_iou: 0.6695\n",
      "Epoch 6/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1419 - mean_iou: 0.6715\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1386 - mean_iou: 0.6717\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1422 - mean_iou: 0.6721\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.1233 - mean_iou: 0.6725\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.1231 - mean_iou: 0.6728\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.1157 - mean_iou: 0.6732\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.1156 - mean_iou: 0.6735\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.1170 - mean_iou: 0.6738\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.1201 - mean_iou: 0.6741\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.1184 - mean_iou: 0.6744\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.1124 - mean_iou: 0.6747\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.1099 - mean_iou: 0.6750\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.1115 - mean_iou: 0.6753\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.1129 - mean_iou: 0.6756\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.1134 - mean_iou: 0.6758\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.1145 - mean_iou: 0.6761\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.1152 - mean_iou: 0.6764 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.1149 - mean_iou: 0.6766\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.1185 - mean_iou: 0.6769\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.1180 - mean_iou: 0.6771\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.1174 - mean_iou: 0.6773\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.1165 - mean_iou: 0.6776\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.1184 - mean_iou: 0.6778\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.1180 - mean_iou: 0.6780\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.1169 - mean_iou: 0.6783\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.1158 - mean_iou: 0.6785\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.1160 - mean_iou: 0.6788\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.1154 - mean_iou: 0.6790\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.1142 - mean_iou: 0.6792\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.1148 - mean_iou: 0.6794\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.1132 - mean_iou: 0.6796\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.1139 - mean_iou: 0.6799\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.1137 - mean_iou: 0.6801\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.1137 - mean_iou: 0.6803\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.1124 - mean_iou: 0.6805 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.1118 - mean_iou: 0.6808\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1117 - mean_iou: 0.6810Epoch 00006: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.1124 - mean_iou: 0.6812 - val_loss: 0.1045 - val_mean_iou: 0.6911\n",
      "Epoch 7/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1014 - mean_iou: 0.6925\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1034 - mean_iou: 0.6926\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1092 - mean_iou: 0.6928\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.1092 - mean_iou: 0.6929\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.1069 - mean_iou: 0.6931\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.1143 - mean_iou: 0.6933\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.1181 - mean_iou: 0.6934\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.1156 - mean_iou: 0.6936\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.1182 - mean_iou: 0.6937\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.1186 - mean_iou: 0.6938\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.1162 - mean_iou: 0.6940\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.1154 - mean_iou: 0.6942\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.1194 - mean_iou: 0.6943\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.1175 - mean_iou: 0.6945\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.1146 - mean_iou: 0.6947\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.1129 - mean_iou: 0.6949\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.1141 - mean_iou: 0.6951 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.1153 - mean_iou: 0.6953\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.1141 - mean_iou: 0.6954\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.1120 - mean_iou: 0.6956\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.1115 - mean_iou: 0.6958\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.1115 - mean_iou: 0.6959\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.1102 - mean_iou: 0.6961\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.1111 - mean_iou: 0.6963\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.1126 - mean_iou: 0.6965\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.1144 - mean_iou: 0.6967\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.1133 - mean_iou: 0.6968\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.1146 - mean_iou: 0.6970\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.1139 - mean_iou: 0.6972\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.1132 - mean_iou: 0.6974\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.1128 - mean_iou: 0.6976\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.1129 - mean_iou: 0.6978\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.1136 - mean_iou: 0.6979\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.1123 - mean_iou: 0.6981\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.1126 - mean_iou: 0.6983 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.1113 - mean_iou: 0.6984\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1102 - mean_iou: 0.6986Epoch 00007: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.1098 - mean_iou: 0.6987 - val_loss: 0.1093 - val_mean_iou: 0.7066\n",
      "Epoch 8/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1105 - mean_iou: 0.7081\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1281 - mean_iou: 0.7083\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1082 - mean_iou: 0.7086\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.1007 - mean_iou: 0.7088\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0998 - mean_iou: 0.7089\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0999 - mean_iou: 0.7092\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.1052 - mean_iou: 0.7093\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.1050 - mean_iou: 0.7095\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.1066 - mean_iou: 0.7096\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.1089 - mean_iou: 0.7098\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.1100 - mean_iou: 0.7099\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.1120 - mean_iou: 0.7100\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.1088 - mean_iou: 0.7101\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.1090 - mean_iou: 0.7103\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.1066 - mean_iou: 0.7104\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.1069 - mean_iou: 0.7105\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.1059 - mean_iou: 0.7107 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.1059 - mean_iou: 0.7109\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.1081 - mean_iou: 0.7110\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.1092 - mean_iou: 0.7112\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.1096 - mean_iou: 0.7113\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.1088 - mean_iou: 0.7114\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.1091 - mean_iou: 0.7116\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.1091 - mean_iou: 0.7117\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.1103 - mean_iou: 0.7118\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.1088 - mean_iou: 0.7120\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.1090 - mean_iou: 0.7121\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.1085 - mean_iou: 0.7122\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.1076 - mean_iou: 0.7124\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.1070 - mean_iou: 0.7125\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.1062 - mean_iou: 0.7127\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.1054 - mean_iou: 0.7128\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.1057 - mean_iou: 0.7130\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.1054 - mean_iou: 0.7131\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.1051 - mean_iou: 0.7133 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.1052 - mean_iou: 0.7134\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1042 - mean_iou: 0.7136Epoch 00008: val_loss improved from 0.10356 to 0.09306, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.1047 - mean_iou: 0.7137 - val_loss: 0.0931 - val_mean_iou: 0.7201\n",
      "Epoch 9/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1065 - mean_iou: 0.7214\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1018 - mean_iou: 0.7216\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1004 - mean_iou: 0.7218\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.1059 - mean_iou: 0.7220\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0951 - mean_iou: 0.7222\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0930 - mean_iou: 0.7224\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0922 - mean_iou: 0.7225\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0919 - mean_iou: 0.7227\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.0920 - mean_iou: 0.7228\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0937 - mean_iou: 0.7229\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0921 - mean_iou: 0.7231\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0946 - mean_iou: 0.7232\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0949 - mean_iou: 0.7234\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0981 - mean_iou: 0.7235\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0983 - mean_iou: 0.7236\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0972 - mean_iou: 0.7238\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0989 - mean_iou: 0.7239 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0980 - mean_iou: 0.7240\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0965 - mean_iou: 0.7241\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0960 - mean_iou: 0.7243\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0961 - mean_iou: 0.7244\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0949 - mean_iou: 0.7245\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0936 - mean_iou: 0.7246\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0935 - mean_iou: 0.7248\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0950 - mean_iou: 0.7249\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0939 - mean_iou: 0.7250\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0928 - mean_iou: 0.7251\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0942 - mean_iou: 0.7252\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0950 - mean_iou: 0.7254\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0959 - mean_iou: 0.7255\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0970 - mean_iou: 0.7256\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0966 - mean_iou: 0.7258\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0983 - mean_iou: 0.7259\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0992 - mean_iou: 0.7260\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0997 - mean_iou: 0.7261 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0998 - mean_iou: 0.7263\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1009 - mean_iou: 0.7264Epoch 00009: val_loss improved from 0.09306 to 0.09204, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.1010 - mean_iou: 0.7265 - val_loss: 0.0920 - val_mean_iou: 0.7315\n",
      "Epoch 10/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1028 - mean_iou: 0.7326\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1123 - mean_iou: 0.7328\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1072 - mean_iou: 0.7328\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0988 - mean_iou: 0.7329\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0916 - mean_iou: 0.7330\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0907 - mean_iou: 0.7331\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0896 - mean_iou: 0.7332\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0966 - mean_iou: 0.7334\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0938 - mean_iou: 0.7335\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0925 - mean_iou: 0.7337\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0915 - mean_iou: 0.7338\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0924 - mean_iou: 0.7339\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0919 - mean_iou: 0.7341\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0932 - mean_iou: 0.7342\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0936 - mean_iou: 0.7343\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0969 - mean_iou: 0.7344\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0970 - mean_iou: 0.7345 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.1013 - mean_iou: 0.7346\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.1012 - mean_iou: 0.7347\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0995 - mean_iou: 0.7348\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0998 - mean_iou: 0.7349\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0991 - mean_iou: 0.7350\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.1012 - mean_iou: 0.7351\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.1014 - mean_iou: 0.7352\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.1008 - mean_iou: 0.7352\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.1019 - mean_iou: 0.7353\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.1021 - mean_iou: 0.7354\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.1037 - mean_iou: 0.7355\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.1032 - mean_iou: 0.7356\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.1042 - mean_iou: 0.7357\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.1043 - mean_iou: 0.7358\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.1043 - mean_iou: 0.7359\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.1032 - mean_iou: 0.7359\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.1026 - mean_iou: 0.7360\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.1029 - mean_iou: 0.7361 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.1040 - mean_iou: 0.7362\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1042 - mean_iou: 0.7363Epoch 00010: val_loss improved from 0.09204 to 0.09123, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.1039 - mean_iou: 0.7364 - val_loss: 0.0912 - val_mean_iou: 0.7402\n",
      "Epoch 11/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0614 - mean_iou: 0.7409\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0571 - mean_iou: 0.7411\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0621 - mean_iou: 0.7412\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0700 - mean_iou: 0.7413\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0746 - mean_iou: 0.7414\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0724 - mean_iou: 0.7415\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0782 - mean_iou: 0.7416\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0822 - mean_iou: 0.7417\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.0863 - mean_iou: 0.7418\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0918 - mean_iou: 0.7419\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0934 - mean_iou: 0.7420\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0929 - mean_iou: 0.7421\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0919 - mean_iou: 0.7422\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0932 - mean_iou: 0.7423\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0943 - mean_iou: 0.7424\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0928 - mean_iou: 0.7425\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0927 - mean_iou: 0.7425 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0925 - mean_iou: 0.7426\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0914 - mean_iou: 0.7427\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0919 - mean_iou: 0.7428\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0936 - mean_iou: 0.7429\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0930 - mean_iou: 0.7430\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0924 - mean_iou: 0.7431\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0929 - mean_iou: 0.7432\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0941 - mean_iou: 0.7433\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0944 - mean_iou: 0.7434\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0942 - mean_iou: 0.7435\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0935 - mean_iou: 0.7435\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0951 - mean_iou: 0.7436\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0949 - mean_iou: 0.7437\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0950 - mean_iou: 0.7438\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0955 - mean_iou: 0.7439\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0947 - mean_iou: 0.7440\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0937 - mean_iou: 0.7441\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0950 - mean_iou: 0.7442 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0950 - mean_iou: 0.7443\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0946 - mean_iou: 0.7444Epoch 00011: val_loss improved from 0.09123 to 0.08880, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0944 - mean_iou: 0.7444 - val_loss: 0.0888 - val_mean_iou: 0.7482\n",
      "Epoch 12/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1060 - mean_iou: 0.7487\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1236 - mean_iou: 0.7488\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1071 - mean_iou: 0.7488\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.1036 - mean_iou: 0.7488\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.1055 - mean_iou: 0.7489\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.1011 - mean_iou: 0.7489\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0979 - mean_iou: 0.7490\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0967 - mean_iou: 0.7491\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.1062 - mean_iou: 0.7492\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.1031 - mean_iou: 0.7493\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.1004 - mean_iou: 0.7494\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.1005 - mean_iou: 0.7495\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.1022 - mean_iou: 0.7496\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.1043 - mean_iou: 0.7496\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.1024 - mean_iou: 0.7497\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.1033 - mean_iou: 0.7498\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.1003 - mean_iou: 0.7499 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0998 - mean_iou: 0.7499\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0990 - mean_iou: 0.7500\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0973 - mean_iou: 0.7501\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0971 - mean_iou: 0.7502\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0963 - mean_iou: 0.7503\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0973 - mean_iou: 0.7503\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0970 - mean_iou: 0.7504\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0959 - mean_iou: 0.7505\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0952 - mean_iou: 0.7506\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0954 - mean_iou: 0.7507\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0949 - mean_iou: 0.7507\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0947 - mean_iou: 0.7508\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0950 - mean_iou: 0.7509\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0959 - mean_iou: 0.7509\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0959 - mean_iou: 0.7510\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0966 - mean_iou: 0.7511\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0953 - mean_iou: 0.7512\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0943 - mean_iou: 0.7512 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0956 - mean_iou: 0.7513\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0951 - mean_iou: 0.7514Epoch 00012: val_loss improved from 0.08880 to 0.07978, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0949 - mean_iou: 0.7514 - val_loss: 0.0798 - val_mean_iou: 0.7547\n",
      "Epoch 13/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0661 - mean_iou: 0.7553\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0776 - mean_iou: 0.7554\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0864 - mean_iou: 0.7555\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0934 - mean_iou: 0.7555\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0946 - mean_iou: 0.7556\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.1017 - mean_iou: 0.7557\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0999 - mean_iou: 0.7557\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.1016 - mean_iou: 0.7558\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.1017 - mean_iou: 0.7559\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.1013 - mean_iou: 0.7560\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.1008 - mean_iou: 0.7561\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0981 - mean_iou: 0.7561\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.1005 - mean_iou: 0.7562\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0963 - mean_iou: 0.7563\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0945 - mean_iou: 0.7563\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0935 - mean_iou: 0.7564\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0925 - mean_iou: 0.7565 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0915 - mean_iou: 0.7566\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0905 - mean_iou: 0.7566\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0912 - mean_iou: 0.7567\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0910 - mean_iou: 0.7568\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0928 - mean_iou: 0.7569\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0933 - mean_iou: 0.7569\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0932 - mean_iou: 0.7570\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0943 - mean_iou: 0.7570\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0948 - mean_iou: 0.7571\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0941 - mean_iou: 0.7572\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0940 - mean_iou: 0.7572\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0938 - mean_iou: 0.7573\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0925 - mean_iou: 0.7573\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0933 - mean_iou: 0.7574\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0926 - mean_iou: 0.7575\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0928 - mean_iou: 0.7575\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0930 - mean_iou: 0.7576\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0924 - mean_iou: 0.7577 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0921 - mean_iou: 0.7577\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0915 - mean_iou: 0.7578Epoch 00013: val_loss improved from 0.07978 to 0.07807, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0922 - mean_iou: 0.7579 - val_loss: 0.0781 - val_mean_iou: 0.7607\n",
      "Epoch 14/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0864 - mean_iou: 0.7612\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0713 - mean_iou: 0.7613\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0831 - mean_iou: 0.7614\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0869 - mean_iou: 0.7615\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0970 - mean_iou: 0.7615\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0964 - mean_iou: 0.7616\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0957 - mean_iou: 0.7617\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0979 - mean_iou: 0.7618\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0984 - mean_iou: 0.7618\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0972 - mean_iou: 0.7619\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0945 - mean_iou: 0.7619\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0931 - mean_iou: 0.7620\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0927 - mean_iou: 0.7620\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0920 - mean_iou: 0.7621\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0918 - mean_iou: 0.7622\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0925 - mean_iou: 0.7622\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0920 - mean_iou: 0.7623 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0908 - mean_iou: 0.7624\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0922 - mean_iou: 0.7624\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0922 - mean_iou: 0.7625\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0914 - mean_iou: 0.7625\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0900 - mean_iou: 0.7626\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0887 - mean_iou: 0.7627\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0877 - mean_iou: 0.7627\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0876 - mean_iou: 0.7628\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0879 - mean_iou: 0.7629\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0892 - mean_iou: 0.7630\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0894 - mean_iou: 0.7630\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0902 - mean_iou: 0.7631\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0892 - mean_iou: 0.7632\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0882 - mean_iou: 0.7632\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0874 - mean_iou: 0.7633\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0886 - mean_iou: 0.7634\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0885 - mean_iou: 0.7634\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0882 - mean_iou: 0.7635 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0882 - mean_iou: 0.7635\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0873 - mean_iou: 0.7636Epoch 00014: val_loss improved from 0.07807 to 0.07578, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0888 - mean_iou: 0.7637 - val_loss: 0.0758 - val_mean_iou: 0.7663\n",
      "Epoch 15/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0841 - mean_iou: 0.7669\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0868 - mean_iou: 0.7669\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0869 - mean_iou: 0.7670\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0865 - mean_iou: 0.7671\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0867 - mean_iou: 0.7671\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0840 - mean_iou: 0.7672\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0841 - mean_iou: 0.7673\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0839 - mean_iou: 0.7673\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.0912 - mean_iou: 0.7674\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0909 - mean_iou: 0.7674\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0874 - mean_iou: 0.7675\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0849 - mean_iou: 0.7675\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0824 - mean_iou: 0.7676\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0834 - mean_iou: 0.7677\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0822 - mean_iou: 0.7677\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0824 - mean_iou: 0.7678\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0814 - mean_iou: 0.7678 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0816 - mean_iou: 0.7679\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0814 - mean_iou: 0.7679\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0821 - mean_iou: 0.7680\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0819 - mean_iou: 0.7681\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0832 - mean_iou: 0.7681\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0837 - mean_iou: 0.7682\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0861 - mean_iou: 0.7682\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0860 - mean_iou: 0.7683\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0849 - mean_iou: 0.7684\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0843 - mean_iou: 0.7684\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0839 - mean_iou: 0.7685\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0828 - mean_iou: 0.7685\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0832 - mean_iou: 0.7686\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0831 - mean_iou: 0.7687\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0837 - mean_iou: 0.7687\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0837 - mean_iou: 0.7688\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0835 - mean_iou: 0.7688\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0837 - mean_iou: 0.7689 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0839 - mean_iou: 0.7689\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0843 - mean_iou: 0.7690Epoch 00015: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0846 - mean_iou: 0.7690 - val_loss: 0.0785 - val_mean_iou: 0.7715\n",
      "Epoch 16/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1112 - mean_iou: 0.7720\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.1118 - mean_iou: 0.7721\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.1000 - mean_iou: 0.7722\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0966 - mean_iou: 0.7722\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0902 - mean_iou: 0.7723\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0917 - mean_iou: 0.7723\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0910 - mean_iou: 0.7724\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0872 - mean_iou: 0.7724\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0823 - mean_iou: 0.7725\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0824 - mean_iou: 0.7725\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0824 - mean_iou: 0.7726\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0868 - mean_iou: 0.7727\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0858 - mean_iou: 0.7727\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0873 - mean_iou: 0.7728\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0868 - mean_iou: 0.7728\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0854 - mean_iou: 0.7729\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0829 - mean_iou: 0.7729 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0817 - mean_iou: 0.7730\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0824 - mean_iou: 0.7730\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0816 - mean_iou: 0.7731\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0829 - mean_iou: 0.7732\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0831 - mean_iou: 0.7732\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0834 - mean_iou: 0.7733\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0858 - mean_iou: 0.7733\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0844 - mean_iou: 0.7733\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0846 - mean_iou: 0.7734\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0844 - mean_iou: 0.7734\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0832 - mean_iou: 0.7735\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0833 - mean_iou: 0.7735\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0834 - mean_iou: 0.7736\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0834 - mean_iou: 0.7736\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0835 - mean_iou: 0.7737\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0836 - mean_iou: 0.7737\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0838 - mean_iou: 0.7738\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0853 - mean_iou: 0.7738 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0843 - mean_iou: 0.7739\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0840 - mean_iou: 0.7739Epoch 00016: val_loss improved from 0.07578 to 0.07059, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0840 - mean_iou: 0.7740 - val_loss: 0.0706 - val_mean_iou: 0.7761\n",
      "Epoch 17/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0908 - mean_iou: 0.7766\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0935 - mean_iou: 0.7766\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0844 - mean_iou: 0.7766\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0789 - mean_iou: 0.7767\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0756 - mean_iou: 0.7768\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0813 - mean_iou: 0.7768\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0811 - mean_iou: 0.7769\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0794 - mean_iou: 0.7769\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0820 - mean_iou: 0.7770\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0844 - mean_iou: 0.7770\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0865 - mean_iou: 0.7771\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0908 - mean_iou: 0.7771\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0926 - mean_iou: 0.7771\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0946 - mean_iou: 0.7772\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0940 - mean_iou: 0.7772\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0935 - mean_iou: 0.7772\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0937 - mean_iou: 0.7773 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0980 - mean_iou: 0.7773\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0974 - mean_iou: 0.7773\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0986 - mean_iou: 0.7773\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0984 - mean_iou: 0.7773\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0990 - mean_iou: 0.7774\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0990 - mean_iou: 0.7774\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0998 - mean_iou: 0.7774\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.1001 - mean_iou: 0.7774\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0992 - mean_iou: 0.7775\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0998 - mean_iou: 0.7775\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0988 - mean_iou: 0.7775\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0992 - mean_iou: 0.7775\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0994 - mean_iou: 0.7776\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.1000 - mean_iou: 0.7776\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.1000 - mean_iou: 0.7776\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0991 - mean_iou: 0.7776\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0999 - mean_iou: 0.7777\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0986 - mean_iou: 0.7777 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0977 - mean_iou: 0.7777\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0971 - mean_iou: 0.7778Epoch 00017: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0968 - mean_iou: 0.7778 - val_loss: 0.0839 - val_mean_iou: 0.7791\n",
      "Epoch 18/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0957 - mean_iou: 0.7794\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0970 - mean_iou: 0.7795\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0966 - mean_iou: 0.7795\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0966 - mean_iou: 0.7795\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0902 - mean_iou: 0.7796\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0887 - mean_iou: 0.7796\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0896 - mean_iou: 0.7797\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0921 - mean_iou: 0.7797\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0924 - mean_iou: 0.7798\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0919 - mean_iou: 0.7798\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0922 - mean_iou: 0.7799\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0900 - mean_iou: 0.7799\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0887 - mean_iou: 0.7800\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0902 - mean_iou: 0.7800\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0944 - mean_iou: 0.7801\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0955 - mean_iou: 0.7801\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0941 - mean_iou: 0.7801 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0942 - mean_iou: 0.7802\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0941 - mean_iou: 0.7802\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0930 - mean_iou: 0.7802\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0957 - mean_iou: 0.7802\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0965 - mean_iou: 0.7803\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0969 - mean_iou: 0.7803\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0977 - mean_iou: 0.7803\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0978 - mean_iou: 0.7803\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0970 - mean_iou: 0.7804\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0958 - mean_iou: 0.7804\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0948 - mean_iou: 0.7804\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0939 - mean_iou: 0.7805\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0936 - mean_iou: 0.7805\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0928 - mean_iou: 0.7805\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0919 - mean_iou: 0.7805\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0910 - mean_iou: 0.7806\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0909 - mean_iou: 0.7806\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0911 - mean_iou: 0.7807 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0901 - mean_iou: 0.7807\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0904 - mean_iou: 0.7807Epoch 00018: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0900 - mean_iou: 0.7807 - val_loss: 0.0737 - val_mean_iou: 0.7824\n",
      "Epoch 19/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0984 - mean_iou: 0.7827\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0792 - mean_iou: 0.7828\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0879 - mean_iou: 0.7828\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0880 - mean_iou: 0.7828\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0885 - mean_iou: 0.7829\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0835 - mean_iou: 0.7829\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0801 - mean_iou: 0.7829\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0835 - mean_iou: 0.7830\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.0835 - mean_iou: 0.7830\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0871 - mean_iou: 0.7830\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0854 - mean_iou: 0.7831\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0855 - mean_iou: 0.7831\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0836 - mean_iou: 0.7831\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0851 - mean_iou: 0.7832\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0860 - mean_iou: 0.7832\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0855 - mean_iou: 0.7832\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0851 - mean_iou: 0.7833 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0835 - mean_iou: 0.7833\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0846 - mean_iou: 0.7834\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0843 - mean_iou: 0.7834\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0843 - mean_iou: 0.7834\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0833 - mean_iou: 0.7835\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0849 - mean_iou: 0.7835\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0853 - mean_iou: 0.7835\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0856 - mean_iou: 0.7836\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0846 - mean_iou: 0.7836\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0852 - mean_iou: 0.7836\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0854 - mean_iou: 0.7837\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0849 - mean_iou: 0.7837\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0852 - mean_iou: 0.7838\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0852 - mean_iou: 0.7838\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0852 - mean_iou: 0.7838\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0847 - mean_iou: 0.7839\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0846 - mean_iou: 0.7839\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0848 - mean_iou: 0.7839 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0857 - mean_iou: 0.7840\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0847 - mean_iou: 0.7840Epoch 00019: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0843 - mean_iou: 0.7840 - val_loss: 0.0718 - val_mean_iou: 0.7857\n",
      "Epoch 20/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0680 - mean_iou: 0.7861\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0633 - mean_iou: 0.7861\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0719 - mean_iou: 0.7861\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0732 - mean_iou: 0.7862\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0837 - mean_iou: 0.7862\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0838 - mean_iou: 0.7863\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0795 - mean_iou: 0.7863\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0826 - mean_iou: 0.7863\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0844 - mean_iou: 0.7863\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0855 - mean_iou: 0.7864\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0870 - mean_iou: 0.7864\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0862 - mean_iou: 0.7864\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0874 - mean_iou: 0.7864\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0862 - mean_iou: 0.7865\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0864 - mean_iou: 0.7865\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0881 - mean_iou: 0.7865\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0862 - mean_iou: 0.7865 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0871 - mean_iou: 0.7866\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0856 - mean_iou: 0.7866\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0856 - mean_iou: 0.7866\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0853 - mean_iou: 0.7867\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0847 - mean_iou: 0.7867\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0842 - mean_iou: 0.7867\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0837 - mean_iou: 0.7868\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0829 - mean_iou: 0.7868\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0839 - mean_iou: 0.7869\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0832 - mean_iou: 0.7869\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0824 - mean_iou: 0.7869\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0816 - mean_iou: 0.7870\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0820 - mean_iou: 0.7870\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0813 - mean_iou: 0.7871\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0808 - mean_iou: 0.7871\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0810 - mean_iou: 0.7871\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0820 - mean_iou: 0.7872\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0818 - mean_iou: 0.7872 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0815 - mean_iou: 0.7872\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0819 - mean_iou: 0.7873Epoch 00020: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0815 - mean_iou: 0.7873 - val_loss: 0.0713 - val_mean_iou: 0.7889\n",
      "Epoch 21/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0530 - mean_iou: 0.7892\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0655 - mean_iou: 0.7893\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0732 - mean_iou: 0.7893\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0747 - mean_iou: 0.7894\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0736 - mean_iou: 0.7894\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0711 - mean_iou: 0.7895\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0734 - mean_iou: 0.7895\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0743 - mean_iou: 0.7895\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0719 - mean_iou: 0.7896\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0751 - mean_iou: 0.7896\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0787 - mean_iou: 0.7897\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0819 - mean_iou: 0.7897\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0819 - mean_iou: 0.7897\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0812 - mean_iou: 0.7898\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0804 - mean_iou: 0.7898\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0799 - mean_iou: 0.7898\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0815 - mean_iou: 0.7899 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0823 - mean_iou: 0.7899\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0814 - mean_iou: 0.7899\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0820 - mean_iou: 0.7900\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0810 - mean_iou: 0.7900\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0805 - mean_iou: 0.7900\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0812 - mean_iou: 0.7901\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0823 - mean_iou: 0.7901\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0835 - mean_iou: 0.7901\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0826 - mean_iou: 0.7902\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0827 - mean_iou: 0.7902\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0832 - mean_iou: 0.7902\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0846 - mean_iou: 0.7903\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0846 - mean_iou: 0.7903\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0841 - mean_iou: 0.7903\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0833 - mean_iou: 0.7904\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0828 - mean_iou: 0.7904\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0825 - mean_iou: 0.7904\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0821 - mean_iou: 0.7904 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0825 - mean_iou: 0.7905\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0820 - mean_iou: 0.7905Epoch 00021: val_loss improved from 0.07059 to 0.06968, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0813 - mean_iou: 0.7905 - val_loss: 0.0697 - val_mean_iou: 0.7919\n",
      "Epoch 22/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1124 - mean_iou: 0.7922\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0913 - mean_iou: 0.7922\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0852 - mean_iou: 0.7922\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0817 - mean_iou: 0.7922\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0770 - mean_iou: 0.7923\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0770 - mean_iou: 0.7923\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0752 - mean_iou: 0.7923\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0753 - mean_iou: 0.7924\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0756 - mean_iou: 0.7924\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0714 - mean_iou: 0.7925\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0700 - mean_iou: 0.7925\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0717 - mean_iou: 0.7925\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0733 - mean_iou: 0.7926\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0734 - mean_iou: 0.7926\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0715 - mean_iou: 0.7926\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0716 - mean_iou: 0.7926\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0708 - mean_iou: 0.7927 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0720 - mean_iou: 0.7927\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0724 - mean_iou: 0.7927\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0736 - mean_iou: 0.7928\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0727 - mean_iou: 0.7928\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0726 - mean_iou: 0.7929\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0725 - mean_iou: 0.7929\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0732 - mean_iou: 0.7929\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0741 - mean_iou: 0.7930\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0744 - mean_iou: 0.7930\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0756 - mean_iou: 0.7930\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0754 - mean_iou: 0.7931\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0746 - mean_iou: 0.7931\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0747 - mean_iou: 0.7931\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0748 - mean_iou: 0.7932\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0756 - mean_iou: 0.7932\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0764 - mean_iou: 0.7932\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0769 - mean_iou: 0.7933\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0768 - mean_iou: 0.7933 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0781 - mean_iou: 0.7933\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0780 - mean_iou: 0.7934Epoch 00022: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0786 - mean_iou: 0.7934 - val_loss: 0.0729 - val_mean_iou: 0.7947\n",
      "Epoch 23/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0862 - mean_iou: 0.7950\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0977 - mean_iou: 0.7950\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0861 - mean_iou: 0.7950\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0844 - mean_iou: 0.7951\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0763 - mean_iou: 0.7951\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0742 - mean_iou: 0.7951\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0757 - mean_iou: 0.7951\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0765 - mean_iou: 0.7952\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.0744 - mean_iou: 0.7952\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0777 - mean_iou: 0.7952\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0766 - mean_iou: 0.7953\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0740 - mean_iou: 0.7953\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0760 - mean_iou: 0.7953\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0772 - mean_iou: 0.7954\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0768 - mean_iou: 0.7954\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0750 - mean_iou: 0.7954\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0744 - mean_iou: 0.7955 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0752 - mean_iou: 0.7955\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0756 - mean_iou: 0.7955\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0755 - mean_iou: 0.7956\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0753 - mean_iou: 0.7956\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0744 - mean_iou: 0.7956\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0741 - mean_iou: 0.7957\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0743 - mean_iou: 0.7957\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0752 - mean_iou: 0.7957\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0762 - mean_iou: 0.7957\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0787 - mean_iou: 0.7958\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0782 - mean_iou: 0.7958\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0775 - mean_iou: 0.7958\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0775 - mean_iou: 0.7959\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0768 - mean_iou: 0.7959\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0769 - mean_iou: 0.7959\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0764 - mean_iou: 0.7959\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0763 - mean_iou: 0.7960\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0773 - mean_iou: 0.7960 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0772 - mean_iou: 0.7960\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0771 - mean_iou: 0.7961Epoch 00023: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0769 - mean_iou: 0.7961 - val_loss: 0.0719 - val_mean_iou: 0.7974\n",
      "Epoch 24/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0843 - mean_iou: 0.7976\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0929 - mean_iou: 0.7976\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0857 - mean_iou: 0.7976\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0854 - mean_iou: 0.7977\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0836 - mean_iou: 0.7977\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0805 - mean_iou: 0.7977\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0770 - mean_iou: 0.7978\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0784 - mean_iou: 0.7978\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0786 - mean_iou: 0.7979\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0799 - mean_iou: 0.7979\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0767 - mean_iou: 0.7979\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0748 - mean_iou: 0.7979\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0766 - mean_iou: 0.7980\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0802 - mean_iou: 0.7980\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0810 - mean_iou: 0.7980\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0789 - mean_iou: 0.7980\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0775 - mean_iou: 0.7981 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0774 - mean_iou: 0.7981\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0769 - mean_iou: 0.7981\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0762 - mean_iou: 0.7982\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0755 - mean_iou: 0.7982\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0742 - mean_iou: 0.7982\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0765 - mean_iou: 0.7982\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0755 - mean_iou: 0.7983\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0753 - mean_iou: 0.7983\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0760 - mean_iou: 0.7983\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0764 - mean_iou: 0.7983\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0785 - mean_iou: 0.7984\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0779 - mean_iou: 0.7984\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0776 - mean_iou: 0.7984\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0773 - mean_iou: 0.7985\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0775 - mean_iou: 0.7985\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0780 - mean_iou: 0.7985\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0770 - mean_iou: 0.7985\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0767 - mean_iou: 0.7986 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0769 - mean_iou: 0.7986\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0770 - mean_iou: 0.7986Epoch 00024: val_loss improved from 0.06968 to 0.06776, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0767 - mean_iou: 0.7986 - val_loss: 0.0678 - val_mean_iou: 0.7998\n",
      "Epoch 25/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:41 - loss: 0.0545 - mean_iou: 0.8000\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0758 - mean_iou: 0.8000\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0721 - mean_iou: 0.8001\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0738 - mean_iou: 0.8001\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0714 - mean_iou: 0.8001\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0680 - mean_iou: 0.8002\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0704 - mean_iou: 0.8002\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0699 - mean_iou: 0.8002\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.0778 - mean_iou: 0.8003\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0826 - mean_iou: 0.8003\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0840 - mean_iou: 0.8003\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0819 - mean_iou: 0.8004\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0851 - mean_iou: 0.8004\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0830 - mean_iou: 0.8004\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0825 - mean_iou: 0.8004\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0805 - mean_iou: 0.8005\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0808 - mean_iou: 0.8005 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0801 - mean_iou: 0.8005\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0794 - mean_iou: 0.8005\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0792 - mean_iou: 0.8006\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0782 - mean_iou: 0.8006\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0771 - mean_iou: 0.8006\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0767 - mean_iou: 0.8006\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0767 - mean_iou: 0.8006\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0763 - mean_iou: 0.8007\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0753 - mean_iou: 0.8007\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0754 - mean_iou: 0.8007\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0748 - mean_iou: 0.8007\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0743 - mean_iou: 0.8008\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0748 - mean_iou: 0.8008\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0753 - mean_iou: 0.8008\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0755 - mean_iou: 0.8008\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0759 - mean_iou: 0.8009\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0754 - mean_iou: 0.8009\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0748 - mean_iou: 0.8009 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0751 - mean_iou: 0.8009\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0750 - mean_iou: 0.8010Epoch 00025: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0751 - mean_iou: 0.8010 - val_loss: 0.0705 - val_mean_iou: 0.8021\n",
      "Epoch 26/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0849 - mean_iou: 0.8023\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0745 - mean_iou: 0.8023\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0720 - mean_iou: 0.8023\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0737 - mean_iou: 0.8023\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0703 - mean_iou: 0.8024\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0655 - mean_iou: 0.8024\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0667 - mean_iou: 0.8024\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0675 - mean_iou: 0.8024\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0679 - mean_iou: 0.8025\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0667 - mean_iou: 0.8025\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0715 - mean_iou: 0.8025\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0751 - mean_iou: 0.8026\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0802 - mean_iou: 0.8026\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0787 - mean_iou: 0.8026\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0793 - mean_iou: 0.8026\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0790 - mean_iou: 0.8027\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0781 - mean_iou: 0.8027 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0786 - mean_iou: 0.8027\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0784 - mean_iou: 0.8027\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0783 - mean_iou: 0.8028\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0777 - mean_iou: 0.8028\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0772 - mean_iou: 0.8028\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0765 - mean_iou: 0.8028\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0747 - mean_iou: 0.8029\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0738 - mean_iou: 0.8029\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0738 - mean_iou: 0.8029\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0736 - mean_iou: 0.8029\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0736 - mean_iou: 0.8030\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0730 - mean_iou: 0.8030\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0733 - mean_iou: 0.8030\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0742 - mean_iou: 0.8030\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0746 - mean_iou: 0.8031\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0746 - mean_iou: 0.8031\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0747 - mean_iou: 0.8031\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0739 - mean_iou: 0.8031 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0739 - mean_iou: 0.8032\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0749 - mean_iou: 0.8032Epoch 00026: val_loss improved from 0.06776 to 0.06697, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0753 - mean_iou: 0.8032 - val_loss: 0.0670 - val_mean_iou: 0.8043\n",
      "Epoch 27/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0713 - mean_iou: 0.8045\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0845 - mean_iou: 0.8046\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0853 - mean_iou: 0.8046\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0795 - mean_iou: 0.8046\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0784 - mean_iou: 0.8046\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0756 - mean_iou: 0.8046\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0801 - mean_iou: 0.8046\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0818 - mean_iou: 0.8046\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0846 - mean_iou: 0.8047\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0791 - mean_iou: 0.8047\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0793 - mean_iou: 0.8047\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0824 - mean_iou: 0.8047\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0800 - mean_iou: 0.8047\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0790 - mean_iou: 0.8047\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0782 - mean_iou: 0.8047\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0782 - mean_iou: 0.8048\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0795 - mean_iou: 0.8048 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0783 - mean_iou: 0.8048\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0777 - mean_iou: 0.8048\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0788 - mean_iou: 0.8048\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0778 - mean_iou: 0.8049\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0783 - mean_iou: 0.8049\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0784 - mean_iou: 0.8049\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0777 - mean_iou: 0.8049\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0768 - mean_iou: 0.8049\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0774 - mean_iou: 0.8050\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0767 - mean_iou: 0.8050\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0761 - mean_iou: 0.8050\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0750 - mean_iou: 0.8050\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0747 - mean_iou: 0.8051\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0745 - mean_iou: 0.8051\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0742 - mean_iou: 0.8051\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0740 - mean_iou: 0.8051\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0749 - mean_iou: 0.8052\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0748 - mean_iou: 0.8052 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0747 - mean_iou: 0.8052\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0744 - mean_iou: 0.8052Epoch 00027: val_loss improved from 0.06697 to 0.06409, saving model to model-dfsbowl2018-1.h5\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0742 - mean_iou: 0.8052 - val_loss: 0.0641 - val_mean_iou: 0.8063\n",
      "Epoch 28/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0442 - mean_iou: 0.8065\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0634 - mean_iou: 0.8066\n",
      " 48/603 [=>............................] - ETA: 1:37 - loss: 0.0746 - mean_iou: 0.8066\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0784 - mean_iou: 0.8066\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0818 - mean_iou: 0.8066\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0843 - mean_iou: 0.8066\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0867 - mean_iou: 0.8067\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0832 - mean_iou: 0.8067\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0788 - mean_iou: 0.8067\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0778 - mean_iou: 0.8067\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0809 - mean_iou: 0.8067\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0820 - mean_iou: 0.8067\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0815 - mean_iou: 0.8068\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0791 - mean_iou: 0.8068\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0778 - mean_iou: 0.8068\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0769 - mean_iou: 0.8068\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0764 - mean_iou: 0.8068 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0766 - mean_iou: 0.8069\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0753 - mean_iou: 0.8069\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0754 - mean_iou: 0.8069\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0762 - mean_iou: 0.8069\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0744 - mean_iou: 0.8069\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0766 - mean_iou: 0.8070\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0771 - mean_iou: 0.8070\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0767 - mean_iou: 0.8070\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0764 - mean_iou: 0.8070\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0763 - mean_iou: 0.8071\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0761 - mean_iou: 0.8071\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0760 - mean_iou: 0.8071\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0752 - mean_iou: 0.8071\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0754 - mean_iou: 0.8071\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0745 - mean_iou: 0.8072\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0745 - mean_iou: 0.8072\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0746 - mean_iou: 0.8072\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0747 - mean_iou: 0.8072 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0753 - mean_iou: 0.8072\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0747 - mean_iou: 0.8073Epoch 00028: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0748 - mean_iou: 0.8073 - val_loss: 0.0646 - val_mean_iou: 0.8082\n",
      "Epoch 29/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0546 - mean_iou: 0.8084\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0678 - mean_iou: 0.8084\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0714 - mean_iou: 0.8084\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0661 - mean_iou: 0.8085\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0729 - mean_iou: 0.8085\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0727 - mean_iou: 0.8085\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0712 - mean_iou: 0.8085\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0755 - mean_iou: 0.8085\n",
      "144/603 [======>.......................] - ETA: 1:19 - loss: 0.0770 - mean_iou: 0.8086\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0753 - mean_iou: 0.8086\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0747 - mean_iou: 0.8086\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0738 - mean_iou: 0.8086\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0769 - mean_iou: 0.8086\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0774 - mean_iou: 0.8087\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0761 - mean_iou: 0.8087\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0748 - mean_iou: 0.8087\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0762 - mean_iou: 0.8087 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0755 - mean_iou: 0.8087\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0744 - mean_iou: 0.8088\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0750 - mean_iou: 0.8088\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0742 - mean_iou: 0.8088\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0744 - mean_iou: 0.8088\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0741 - mean_iou: 0.8089\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0749 - mean_iou: 0.8089\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0747 - mean_iou: 0.8089\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0761 - mean_iou: 0.8089\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0769 - mean_iou: 0.8089\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0756 - mean_iou: 0.8090\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0758 - mean_iou: 0.8090\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0766 - mean_iou: 0.8090\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0765 - mean_iou: 0.8090\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0776 - mean_iou: 0.8090\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0774 - mean_iou: 0.8091\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0772 - mean_iou: 0.8091\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0768 - mean_iou: 0.8091 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0764 - mean_iou: 0.8091\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0760 - mean_iou: 0.8091Epoch 00029: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0756 - mean_iou: 0.8091 - val_loss: 0.0698 - val_mean_iou: 0.8100\n",
      "Epoch 30/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1025 - mean_iou: 0.8102\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0836 - mean_iou: 0.8102\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0802 - mean_iou: 0.8103\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0770 - mean_iou: 0.8103\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0812 - mean_iou: 0.8103\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0783 - mean_iou: 0.8103\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0822 - mean_iou: 0.8104\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0789 - mean_iou: 0.8104\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0793 - mean_iou: 0.8104\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0792 - mean_iou: 0.8104\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0780 - mean_iou: 0.8104\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0772 - mean_iou: 0.8104\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0770 - mean_iou: 0.8105\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0798 - mean_iou: 0.8105\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0807 - mean_iou: 0.8105\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0812 - mean_iou: 0.8105\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0829 - mean_iou: 0.8105 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0811 - mean_iou: 0.8105\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0810 - mean_iou: 0.8106\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0796 - mean_iou: 0.8106\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0794 - mean_iou: 0.8106\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0787 - mean_iou: 0.8106\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0786 - mean_iou: 0.8106\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0779 - mean_iou: 0.8106\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0777 - mean_iou: 0.8107\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0783 - mean_iou: 0.8107\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0782 - mean_iou: 0.8107\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0772 - mean_iou: 0.8107\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0768 - mean_iou: 0.8107\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0761 - mean_iou: 0.8107\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0751 - mean_iou: 0.8107\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0750 - mean_iou: 0.8108\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0753 - mean_iou: 0.8108\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0751 - mean_iou: 0.8108\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0746 - mean_iou: 0.8108 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0749 - mean_iou: 0.8108\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0741 - mean_iou: 0.8109Epoch 00030: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0739 - mean_iou: 0.8109 - val_loss: 0.0641 - val_mean_iou: 0.8117\n",
      "Epoch 31/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.1033 - mean_iou: 0.8119\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0896 - mean_iou: 0.8119\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0795 - mean_iou: 0.8119\n",
      " 64/603 [==>...........................] - ETA: 1:34 - loss: 0.0791 - mean_iou: 0.8119\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0788 - mean_iou: 0.8120\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0799 - mean_iou: 0.8120\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0838 - mean_iou: 0.8120\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0818 - mean_iou: 0.8120\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0803 - mean_iou: 0.8120\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0781 - mean_iou: 0.8120\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0769 - mean_iou: 0.8121\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0783 - mean_iou: 0.8121\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0798 - mean_iou: 0.8121\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0776 - mean_iou: 0.8121\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0780 - mean_iou: 0.8121\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0780 - mean_iou: 0.8121\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0770 - mean_iou: 0.8121 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0774 - mean_iou: 0.8122\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0774 - mean_iou: 0.8122\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0786 - mean_iou: 0.8122\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0775 - mean_iou: 0.8122\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0762 - mean_iou: 0.8122\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0764 - mean_iou: 0.8123\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0749 - mean_iou: 0.8123\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0744 - mean_iou: 0.8123\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0731 - mean_iou: 0.8123\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0734 - mean_iou: 0.8123\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0729 - mean_iou: 0.8124\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0733 - mean_iou: 0.8124\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0733 - mean_iou: 0.8124\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0741 - mean_iou: 0.8124\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0732 - mean_iou: 0.8124\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0737 - mean_iou: 0.8125\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0730 - mean_iou: 0.8125\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0725 - mean_iou: 0.8125 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0730 - mean_iou: 0.8125\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0734 - mean_iou: 0.8125Epoch 00031: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0729 - mean_iou: 0.8125 - val_loss: 0.0651 - val_mean_iou: 0.8134\n",
      "Epoch 32/50\n",
      "\n",
      " 16/603 [..............................] - ETA: 1:42 - loss: 0.0370 - mean_iou: 0.8135\n",
      " 32/603 [>.............................] - ETA: 1:39 - loss: 0.0358 - mean_iou: 0.8135\n",
      " 48/603 [=>............................] - ETA: 1:36 - loss: 0.0522 - mean_iou: 0.8136\n",
      " 64/603 [==>...........................] - ETA: 1:33 - loss: 0.0524 - mean_iou: 0.8136\n",
      " 80/603 [==>...........................] - ETA: 1:31 - loss: 0.0519 - mean_iou: 0.8136\n",
      " 96/603 [===>..........................] - ETA: 1:28 - loss: 0.0560 - mean_iou: 0.8136\n",
      "112/603 [====>.........................] - ETA: 1:25 - loss: 0.0659 - mean_iou: 0.8136\n",
      "128/603 [=====>........................] - ETA: 1:22 - loss: 0.0679 - mean_iou: 0.8136\n",
      "144/603 [======>.......................] - ETA: 1:20 - loss: 0.0656 - mean_iou: 0.8137\n",
      "160/603 [======>.......................] - ETA: 1:17 - loss: 0.0674 - mean_iou: 0.8137\n",
      "176/603 [=======>......................] - ETA: 1:14 - loss: 0.0670 - mean_iou: 0.8137\n",
      "192/603 [========>.....................] - ETA: 1:11 - loss: 0.0657 - mean_iou: 0.8137\n",
      "208/603 [=========>....................] - ETA: 1:08 - loss: 0.0669 - mean_iou: 0.8137\n",
      "224/603 [==========>...................] - ETA: 1:06 - loss: 0.0682 - mean_iou: 0.8137\n",
      "240/603 [==========>...................] - ETA: 1:03 - loss: 0.0694 - mean_iou: 0.8138\n",
      "256/603 [===========>..................] - ETA: 1:00 - loss: 0.0706 - mean_iou: 0.8138\n",
      "272/603 [============>.................] - ETA: 57s - loss: 0.0714 - mean_iou: 0.8138 \n",
      "288/603 [=============>................] - ETA: 54s - loss: 0.0711 - mean_iou: 0.8138\n",
      "304/603 [==============>...............] - ETA: 52s - loss: 0.0721 - mean_iou: 0.8138\n",
      "320/603 [==============>...............] - ETA: 49s - loss: 0.0730 - mean_iou: 0.8138\n",
      "336/603 [===============>..............] - ETA: 46s - loss: 0.0718 - mean_iou: 0.8138\n",
      "352/603 [================>.............] - ETA: 43s - loss: 0.0721 - mean_iou: 0.8139\n",
      "368/603 [=================>............] - ETA: 40s - loss: 0.0731 - mean_iou: 0.8139\n",
      "384/603 [==================>...........] - ETA: 38s - loss: 0.0730 - mean_iou: 0.8139\n",
      "400/603 [==================>...........] - ETA: 35s - loss: 0.0730 - mean_iou: 0.8139\n",
      "416/603 [===================>..........] - ETA: 32s - loss: 0.0717 - mean_iou: 0.8139\n",
      "432/603 [====================>.........] - ETA: 29s - loss: 0.0723 - mean_iou: 0.8139\n",
      "448/603 [=====================>........] - ETA: 27s - loss: 0.0720 - mean_iou: 0.8140\n",
      "464/603 [======================>.......] - ETA: 24s - loss: 0.0719 - mean_iou: 0.8140\n",
      "480/603 [======================>.......] - ETA: 21s - loss: 0.0716 - mean_iou: 0.8140\n",
      "496/603 [=======================>......] - ETA: 18s - loss: 0.0731 - mean_iou: 0.8140\n",
      "512/603 [========================>.....] - ETA: 15s - loss: 0.0731 - mean_iou: 0.8140\n",
      "528/603 [=========================>....] - ETA: 13s - loss: 0.0733 - mean_iou: 0.8140\n",
      "544/603 [==========================>...] - ETA: 10s - loss: 0.0731 - mean_iou: 0.8141\n",
      "560/603 [==========================>...] - ETA: 7s - loss: 0.0731 - mean_iou: 0.8141 \n",
      "576/603 [===========================>..] - ETA: 4s - loss: 0.0739 - mean_iou: 0.8141\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.0741 - mean_iou: 0.8141Epoch 00032: val_loss did not improve\n",
      "\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0742 - mean_iou: 0.8141 - val_loss: 0.0694 - val_mean_iou: 0.8148\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dfsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe0b8d7ab70>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPD1bKCrIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0b8db9ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe0b8ce3e48>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0b8d8a978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history['val_mean_iou'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_lou' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-6ca553357c3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Predict on train, val and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model-dfsbowl2018-1.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'mean_lou'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmean_lou\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpreds_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpreds_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpreds_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_lou' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model-dfsbowl2018-1.h5', custom_objects={'mean_lou': mean_lou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test_t)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[1]), (sizes_test[i][0], sizes_test[i][1]), mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
